{"pages":[],"posts":[{"title":"Docker-alpine镜像导致的问题","text":"前段时间接到一个需求，将现有的一个项目容器化部署。经过一段时间的折腾，总算成功的跑起来了。但是最近发现一个问题：图形验证码没法显示了。 通过查找日志发现以下异常堆栈： 12345678910111213141516171819202122java.lang.NullPointerException: null at sun.awt.X11FontManager.getDefaultPlatformFont(X11FontManager.java:779) at sun.font.SunFontManager$2.run(SunFontManager.java:433) at java.security.AccessController.doPrivileged(Native Method) at sun.font.SunFontManager.&lt;init&gt;(SunFontManager.java:376) at sun.awt.X11FontManager.&lt;init&gt;(X11FontManager.java:32) at sun.reflect.GeneratedConstructorAccessor62.newInstance(Unknown Source) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:526) at java.lang.Class.newInstance(Class.java:383) at sun.font.FontManagerFactory$1.run(FontManagerFactory.java:83) at java.security.AccessController.doPrivileged(Native Method) at sun.font.FontManagerFactory.getInstance(FontManagerFactory.java:74) at java.awt.Font.getFont2D(Font.java:490) at java.awt.Font.access$000(Font.java:224) at java.awt.Font$FontAccessImpl.getFont2D(Font.java:228) at sun.font.FontUtilities.getFont2D(FontUtilities.java:180) at sun.java2d.SunGraphics2D.checkFontInfo(SunGraphics2D.java:645) at sun.java2d.SunGraphics2D.getFontInfo(SunGraphics2D.java:806) at sun.java2d.pipe.GlyphListPipe.drawString(GlyphListPipe.java:50) at sun.java2d.SunGraphics2D.drawString(SunGraphics2D.java:2887)... 结合源码发现，应该是无法获取到字体导致的异常： 1graphics.setFont(new Font(&quot;Default&quot;, Font.PLAIN, fsize)); 由于代码没有做出过变更，所以毫无疑问，应该是环境的问题了。 于是我进入Dokcer容器查看相关字体： 12docker exec -it containerId bashfc-list 发现无任何内容输出。经过一番查找，解决办法如下： 进入容器安装字体（只能临时解决，当重新构建后，字体会丢失） 1apk add --update ttf-dejavu fontconfig &amp;&amp; rm -rf /var/cache/apk/* 修改Dockerfile 在构建镜像时安装字体（会影响构建速度，安装字体比较慢） 1RUN apk add --update ttf-dejavu fontconfig &amp;&amp; rm -rf /var/cache/apk/* 更改基础镜像（推荐） 我这边出问题的容器是基于tomcat:8.0-jre7-alpine构建的，alpine tag的镜像比较小，比较干净。 我到docker hub上找到了类似的镜像，slim tag的。 修改Dockerfile，将FROM tomcat:8.0-jre7-alpine 改为 FROM tomcat:8.0-jre7-slim即可。","link":"/archives/f3674cca.html"},{"title":"Docker使用overlay网络遇到的问题","text":"一般我们使用Overlay网络都是涉及到多台主机中的Docker容器通信问题。 Docker Overlay 一切准备就绪后，使用docker-compose 启动容器。 在一个业务服务的容器日志里面发现无法连接的Zookeeper，错误是： 1java.net.NoRouteToHostException: No route to host 在容器中尝试ping 10.0.0.3 容器，发现不通： 1234PING zookeeper (10.0.0.3) 56(84) bytes of data.From 85789ac6e6a8 (10.0.0.8) icmp_seq=1 Destination Host UnreachableFrom 85789ac6e6a8 (10.0.0.8) icmp_seq=2 Destination Host UnreachableFrom 85789ac6e6a8 (10.0.0.8) icmp_seq=3 Destination Host Unreachable 刚开始查询了一些资料后，以为是防火墙(CentOS7)问题，于是查看了防火墙状态： 1firewall-cmd --state 结果防火墙压根没开： 1not running 由于之前没有详细查看docker overlay网络的使用限制，一直以为只要docker的版本保持在1.9.1+就可以了。后来又查了下，发现还有一个限制：内核版本大于等于3.16。于是赶紧查看了下内核版本： 12# uname -r3.10.0-514.10.2.el7.x86_64 果然内核版本低了，于是开始升级内核。 导入elrepo的key，然后安装elrepo的yum源： 12sudo rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgsudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm 列出可用的内核相关包： 1yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available lt为长期维护版本，mt为稳定版本，可以看到最新的稳定版本为： 15.2.10-1.el7.elrepo 开始升级内核（以后可以直接执行这句）： 1sudo yum -y --enablerepo=elrepo-kernel install kernel-ml.x86_64 kernel-ml-devel.x86_64 升级完后需要重启一下： 1reboot 再次查看内核： 12uname -r3.10.0-514.10.2.el7.x86_64 WTF，为什么还是老的?原来是启动的时候还是默认选择了老的内核，这里需要重新设置一下启动时的默认内核： 首先查看当前都有哪些启动项： 1234cat /boot/grub2/grub.cfg |grep menuentrymenuentry 'CentOS Linux (5.2.10-1.el7.elrepo.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-514.6.2.el7.x86_64-advanced-07151862-c2b9-45dc-bf7a-af8d2a6fa6c1' {menuentry 'CentOS Linux (3.10.0-514.10.2.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-3.10.0-514.6.2.el7.x86_64-advanced-07151862-c2b9-45dc-bf7a-af8d2a6fa6c1' { 设置默认选项（需要升级为root用户）： 1grub2-set-default 'CentOS Linux (5.2.10-1.el7.elrepo.x86_64) 7 (Core)' 再次重启，重启后查看内核： 12uname -r5.2.10-1.el7.elrepo.x86_64 OK，内核成功升级，再次启动Docker试试（别忘了启动服务发现，我这里是ETCD）: ETCD启动: 1./etcd --name docker-node3 --initial-advertise-peer-urls http://10.208.10.17:2380 --listen-peer-urls http://10.208.10.17:2380 --listen-client-urls http://10.208.10.17:2379,http://127.0.0.1:2379 --advertise-client-urls http://10.208.10.17:2379 --initial-cluster-token etcd-cluster --initial-cluster docker-node1=http://10.208.10.14:2380,docker-node2=http://10.208.10.16:2380,docker-node3=http://10.208.10.17:2380 --initial-cluster-state new &amp; Docker 启动： 1sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://10.208.10.14:2379 --cluster-advertise=10.208.10.14:2375 &amp; 当所有主机都完成上述操作时，发现容器间总算可以互通了。 其他问题： 1error locating sandbox id c43437e6300a0c6ea20d2d9f95bbe318e557d1eedfa585ab5218345eeef32a36: sandbox c43437e6300a0c6ea20d2d9f95bbe318e557d1eedfa585ab5218345eeef32a36 not found 1could not get network sandbox (oper true): failed get network namespace &quot;&quot; 最好删除之前创建的network和container，否则可能出现其他问题。 不同主机上的容器间使用hostname或者container name通信好像有问题，可以使用docker swarm来解决。 参考资料： https://www.centos.bz/2017/08/upgrade-centos-7-6-kernel-to-4-12-4/","link":"/archives/1c99e54f.html"},{"title":"Docker多主机容器间ping不通的问题","text":"之前记录过一个因为内核版本过低导致Docker overlay网络不通的问题。后来又遇到一个由于粗心导致的网络不通的问题。 问题的现象是这样的，创建了overlay网络后，同一台主机上的容器间可以ping通。而不同主机上的容器ping的结果是： 1234PING zookeeper (10.0.0.3) 56(84) bytes of data.From 85789ac6e6a8 (10.0.0.8) icmp_seq=1 Destination Host UnreachableFrom 85789ac6e6a8 (10.0.0.8) icmp_seq=2 Destination Host UnreachableFrom 85789ac6e6a8 (10.0.0.8) icmp_seq=3 Destination Host Unreachable Google一通之后，未找到满意答案，觉得很是奇怪，灵光一现查看 etcd 上的节点： 1etcdctl ls /docker/nodes 发现只有一个： 1/docker/nodes/10.208.10.14:2375 后来想起来了原来在启动docker的时候，使用的命令忘了改 –cluster-advertise –cluster-advertise：告知集群当前的连接地址 1sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://10.208.10.14:2379 --cluster-advertise=当前host:2375 &amp;","link":"/archives/d7132b2f.html"},{"title":"Go Module 引入本地自定义包","text":"文章转载至 小一辈无产阶级码农 最近由于项目要求，需要对 IPFS 源码进行修改，由于自己在此之前没有接触过 Go 语言，在使用 go mod 导入本地自己开发的工具包的时候折腾了好久才搞定。 记录一下，以备后期查阅。 Go 语言的 Module 新特性是在 go1.11 的发布之后才支持的，这是 Go 语言新的一套依赖管理系统。 文章导读 1. 启用 Go Module 2. 创建 Go Module 3. Go Module 版本规则 4. 引入本地依赖包 5. 使用 replace 将远程包替换为本地包服务 1. 启用 Go Module首先在默认情况下，$GOPATH 默认情况下是不支持 go mudules 的，当你执行 go mod init 的时候会遇到如下错误： go: modules disabled inside GOPATH/src by GO111MODULE=auto; see ‘go help modules’ 我们需要在执行 go mod 命令之前，导出 GO111MODULE 环境变量，你可以直接临时一次性导出， 为了后面方便，建议直接在 ~/.bashrc 文件中导出， 在文件末尾加入： 1export GO111MODULE=on Bash 从这也表明了 go 将来是要利用 modules 机制去消灭 $GOPATH 的。 2. 创建 Go Module我们现在 $GOPATH 下面先创建一个项目，并初始化 module 1234mkdir $GOPATH/src/gitee.com/rockyang/testmod -pcd $GOPATH/src/gitee.com/rockyang/test-gomodgo mod init gitee.com/rockyang/test-gomodgo: creating new go.mod: module gitee.com/rockyang/testmod Bash 这时，我们新建的项目已经成为了一个 module 了，我们可以在项目中随便写几个函数导出测试。 Note: 我这里使用的是码云做项目托管，没有使用 github，国内码云确实比 github 快得多。 接下来你可以选择把项目推送到远程仓库，如果你的仓库是公开的话，别人就是可以直接使用 go get 命令去下载你的项目了。 如果是私有项目只想给内部使用，则你可以参考我的这篇博客的做法。Go Module 使用私有仓库作为项目依赖包 3. Go Module 版本规则go modules 是一个版本化依赖管理系统，版本需要遵循一些规则，打开一个 go.mod 文件，你会发现类似下面的依赖规则： 12345678require ( github.com/filecoin-project/go-leb128 v0.0.0-20190212224330-8d79a5489543 github.com/golang/mock v1.2.0 // indirect github.com/ipfs/go-bitswap v0.0.2 github.com/libp2p/go-stream-muxer v0.0.1 github.com/minio/blake2b-simd v0.0.0-20160723061019-3f5f724cb5b1 gotest.tools v2.2.0+incompatible // indirect) Bash 依赖规则由两个部分组成，前面一部分是包路径，后面一部分表示的是版本号。 你会发现有两种版本号，一种是我们很熟悉的 git 标签，比如 v0.0.2，另一种就比较复杂一些，它是：版本号 + 时间戳 +hash 比如：v0.0.0-20190212224330-8d79a5489543，它其实是精准的对应着一个 git log 记录，后面的哈希是去提交哈希的前 12 位。 比如我当前的提交记录是这样的： 1234$ git log commit 4c55783279db32be4f02e193713d5a862b96db85 (HEAD -&gt; master, origin/master)Author: yangjian &lt;yangjian102621@gmail.com&gt;Date: Mon Jun 10 18:34:14 2019 +0800 Bash 则我的最新版本号应该为 v0.0.0-20190610103414-4c55783279db 4. 引入本地依赖包前面铺垫了这么多，接下来回到我们的主题，我该怎样使用我们自己开发的工具包呢？ 假设我们有一个新的项目 testmod-demo，现在想要在新的项目中使用 testmod 中的工具包，那么首先我们需要使用 go mod 初始化该项目： 12cd testmod-demogo mod init gitee.com/rockyang/testmod-demo Bash 初始化之后会在当前项目根目录生成一个 go.mod，接下来我们有两种方式去引入 testmod 包，一种是直接修改 go.mod 文件，在 require 配置中添加上 1gitee.com/rockyang/testmod v0.0.0-20190610103414-4c55783279db Bash 或者使用 go mod edit 命令修改依赖 12go mod edit -require=&quot;gitee.com/rockyang/testmod@v0.0.0-20190610103414-4c55783279db&quot;go mod tidy # 整理依赖包 Bash 5. 使用 replace 将远程包替换为本地包服务这时如果你执行 go build 的时候会报错，提示找不到 gitee.com/rockyang/testmod，是因为你没有把仓库推送到远程，所以无法下载。 go module 提供了另外一个方案, 使用 replace, 编辑 go.mod 文件，在最后面添加：replace gitee.com/rockyang/testmod =&gt; /gopath/src/gitee.com/rockyang/testmod 1234567891011module gitee.com/rockyang/testmod-demogo 1.12require ( github.com/gin-gonic/gin v1.3.0 gitee.com/rockyang/testmod@v0.0.0-20190610103414-4c55783279db golang.org/x/net v0.0.0-20190320064053-1272bf9dcd53 // indirect)replace gitee.com/rockyang/testmod =&gt; /gopath/src/gitee.com/rockyang/testmod Bash 这里的 /gopath/src/gitee.com/rockyang/testmod 是本地的包路径 然后再执行 go build 你会看到你想要的结果。 以上为原作者原文，转载这篇文章的原因是因为Golang1.13发布了，看到了其中一个新特新GOPRIVATE 可以搭配 GOPROXY 对私有模块更细粒度的控制。","link":"/archives/c8d527a1.html"},{"title":"Golang中一些设定","text":"格式化时间不是用yyyy MM DD HH mm ss sss等在其他语言中常见的符号。而是：2006-01-02 15:04:05 123now := time.Now()nowRight := now.Format(&quot;2006-01-02 15:04:05&quot;) 完整UTC为：2006-01-02T15:04:05-07:00 map 每次遍历都是无序的。据说是为了让开发者不要依赖不是很可靠的map有序遍历，索性改成了无序的。正确的做法是获取到key，然后排序key，然后在遍历map： 12345678var keys []intfor k,_ :=range map{ keys = append(keys, k)}sort.Ints(keys)for _,v:=range keys{ fmt.Printf(&quot;%d-%d\\n&quot;,v,aa[v])} slice 不初始化不能赋值，但是用append可以 12345var s []ints[0]=100//报错，runtime error: index out of ranges=append(s,100)//正确通过，append里面可能对s做的初始化 go get [-u -v]go build : 编译出可执行文件go install : go build + 把编译后的可执行文件放到GOPATH/bin目录下go get : git clone + go install Golang不支持函数的重载 可以多个变量一起赋值，利用这个特性，可以很简单的实现斐波拉契数列 123456a:=1b:=1for i:=0;i&lt;10;i++{fmt.Println(a)a,b=b,a+b} Golang中的方法与其它语言中不一样，其它语言一般直接定义在Class 或者struct中，在Golang中是分离的。 12345678910func (recevier type) methodName(参数列表)(返回值列表){}recevier type 是不是指针也有很大影响func (i *integer) set(val integer){ *i = val}var j integerj.set(10) 读取chan的两种方式 1234567891011121314close(ch)//第一种： for{ b,ok:=&lt;-ch if !ok{ fmt.Println(&quot;chan is closed!&quot;) break } fmt.Println(b)}//第二种：for v:=range ch { fmt.Println(v)} go 不支持三目(三元)运算符","link":"/archives/f11a2580.html"},{"title":"golang写文件异常invalid argument","text":"123dst, err := os.OpenFile(path, os.O_CREATE|os.O_APPEND|os.O_RDWR, 0644)defer dst.Close()n, err := dst.Write(buffer.Buffer[0:n]) 上面是一段很简单的代码，但是在频繁调用的时候报错了了:invalid argument 这个错误着实太误导人了，让我以为是使用的姿势不对，后来发现没有问题，于是开始debug，后来在下面一段代码中发现了真正的问题： 12345678910111213func CreateFile(name *uint16, access uint32, mode uint32, sa *SecurityAttributes, createmode uint32, attrs uint32, templatefile int32) (handle Handle, err error) { r0, _, e1 := Syscall9(procCreateFileW.Addr(), 7, uintptr(unsafe.Pointer(name)), uintptr(access), uintptr(mode), uintptr(unsafe.Pointer(sa)), uintptr(createmode), uintptr(attrs), uintptr(templatefile), 0, 0) handle = Handle(r0) if handle == InvalidHandle { if e1 != 0 { err = errnoErr(e1) } else { err = EINVAL } } return} 这里给出了真正的原因： 1err = errnoErr(e1)//这个地方给出了真正的错误：ERROR_SHARING_VIOLATION (32) 查询微软https://docs.microsoft.com/en-us/windows/win32/debug/system-error-codes--0-499-文档， 这个错误是因为： 1The process cannot access the file because it is being used by another process. 也就是说，在OpenFile一个文件的时候，之前使用的这个文件的file descriptor 并真正没有释放，所以出错了。 而Golang上层的错误并没有给出明确的错误。","link":"/archives/848ae75e.html"},{"title":"Golang常用的第三方包","text":"Mysql Drivergo get -u github.com/go-sql-driver/mysql SQL Librarygo get github.com/jmoiron/sqlx Redis Librarygo get github.com/gomodule/redigo/redis Kafka Librarygo get github.com/Shopify/sarama Etcd Librarygo get go.etcd.io/etcd/client TOML Library go get github.com/BurntSushi/toml toml一个比yaml更简洁更方便的一种配置文件格式 未完待续… 2019/08/19 最近发现github上一个库整理的比较全，可以参考：https://github.com/avelino/awesome-go对应中文版：https://github.com/jobbole/awesome-go-cn","link":"/archives/4c4ac8cd.html"},{"title":"Visual Studio Code Golang环境配置","text":"前提是已经装好了Go，并且正确配置了GOROOT、GOPATH。不知道这两个是什么东西的，建议先搞明白。 1.Visual Studio Code 安装Golang扩展 2.安装Golang所需插件Ctrl+Shift+P 选择需要安装的插件（主要是代码提示，代码规范等插件），可全选 由于国内网络环境，就算你FQ，这一步也不一定能够安装成功。 所以一般采取如下方式：cd %GOPATH%\\src\\github.com\\golang如果src目录下面没有github.com\\golang请自行创建执行： 1git clone [https://github.com/golang/tools.git](https://github.com/golang/tools.git) tools 当下载完成后，你会发现%GOPATH%\\src\\github.com\\golang多了一个tools目录需要把tools目录下的所有文件拷贝到%GOPATH%\\src\\golang.org\\x\\tools下，如果没有自行创建 下面安装无法安装的插件（可以先通过vscode安装，然后将不成功的再按照此方法安装）开始安装：切换到GOPATH目录下，执行相关的go install 命令go install github.com/mdempsky/gocodego install github.com/uudashr/gopkgs/cmd/gopkgsgo install github.com/fatih/gomodifytagsgo install github.com/haya14busa/goplay/cmd/goplaygo install github.com/derekparker/delve/cmd/dlvgo install github.com/ramya-rao-a/go-outlinego install github.com/acroca/go-symbolsgo install golang.org/x/tools/cmd/gurugo install golang.org/x/tools/cmd/gorenamego install github.com/josharian/implgo install github.com/rogpeppe/godefgo install github.com/sqs/goreturnsgo install github.com/golang/lint/golintgo install github.com/cweill/gotests/gotests 上面的包有可能存在更新，以实际clone下来的为准。","link":"/archives/bbb37996.html"},{"title":"一张图说明Golang的并发模型MPG","text":"Golang 天生支持并发，Goroutine是Go 最吸引人的地方，采用的是CSP并发通信模型。到底Go是怎么支持高并发的呢？这里就需要说一说Golang 的MPG模型。 M 代表着一个内核线程 ，一个M就是一个内核线程，goroutine就是跑在M之上的 P 代表着(Processor)处理器， 它的主要用途就是用来执行goroutine的，所以它也维护了一个可运行的goroutine队列，和自由的goroutine队列，里面存储了所有需要它来执行的goroutine。 G 代表着goroutine 实际的数据结构，并维护者goroutine 需要的栈、程序计数器以及它所在的M等信息。 Sched 代表着一个调度器 它维护有存储空闲的M队列和空闲的P队列，可运行的G队列，自由的G队列以及调度器的一些状态信息等。 一张图就可以说明MPG模型： 图中的“土拨鼠”代表的就是M，“推车”代表的是P，“木块”代表的就是G。在这张图外还存在一个特殊的”土拨鼠“这个”土拨鼠“就是”包工头“Sched。 从图中我们可以看到“土拨鼠“不停地将“木块“搬运到“推车“上，然后推去烧。在这个过程中可能出现“土拨鼠“因为累坏了，而处理的速度变慢的情况，这个时候“包工头“就出现了，“包工头“非常体贴的将这个“土拨鼠“的“推车“交给其他“土拨鼠“去处理。如果一个“土拨鼠“的“推车“里面的“木块“装的太多，“包工头“也会让其它的“土拨鼠“去帮忙拿出一些来。当“包工头“发现现有的“土拨鼠“已经忙不过来的时候，就回去找一些新的“土拨鼠“过来，并给他们配发“推车“。直到所有的“木块“都烧完为止。 上面说到的几种情况： “土拨鼠”累坏了，形容的是IO等耗时的操作。 其他“土拨鼠”帮忙，形容的是工作窃取算法（work stealing），这个算法在很多语言中都有应用，例如Java中的Fork/Foin。 在Golang中土拨鼠默认的数量是CPU的核数，土拨鼠通过CSP模型沟通。 参考资料： https://zhuanlan.zhihu.com/p/22352969","link":"/archives/79f4a57c.html"},{"title":"传递值与传递指针","text":"假如有一个变量： 1var a int = 0 这时要通过一个函数set改变a的值: 123func set (a int){ a = 1} 在main函数中调用： 12345func main(){ var a int = 0 set(a) fmt.Println(a)} 最终a的结果还是0。这是因为传递到set方法中的是a变量值得拷贝： 12345678910var a int = 0//假设a变量地址为 0xc00005e1b0set(a)//这里实际传递的是set(0)//在set函数中func set (a int){ //a的变量地址为0xc00005e1d1，注意与外面的a不是一个地址，这是两个变量 //这一行改变的实际上是0xc00005e1d1 这个地址的值 a = 1} 看看内存中的情况： 如何解决这个问题？在Golang中只需要传递指针即可，对上面的代码做出修改： 12345var a int = 0set(&amp;a) //这里变成&amp;afunc set(a *int){//这里变成a *int*a = 1//这里变成*a=1} 再来看看内存中的情况： 注意：一定要是*a =1这才意味着改变的是a对应地址指向的值如果是a =1首先肯定编译不通过，因为a变量需要指向的是一个地址，而1不是地址。其次如果a(里面的)=另外一个地址，那么外面a还是不会变化： 使用时一定要注意细节，一不留神就出问题。 原创，如有雷同纯属偶合。","link":"/archives/ffe16d99.html"},{"title":"跟着B站学Golang(admin-ep-saga)","text":"本文完全出于学习的目的，如有异议，请联系删除。 之前XL事件流出的优秀代码太多了，这次选择的是一个好像与具体业务无关的模块(admin-ep-saga)来进行学习。 首先看看目录结构： 这么多先看哪一个呢？在不知道具体每个包是干什么的情况下，只好一个一个的看了。 先看看api下有些什么： 不得不说这个目录的结构相当规范呀，虽然我没有点开具体文件，但是仅仅从目录名和文件名就能猜出这个目录下是干什么的： 应该是使用了grpc框架和protobuf协议定义的接口。这个暂时先放一边，我需要先找到程序入口，这样才能一步一步的学习优秀代码是如何编写的。 接下来打开cmd: 这个目录下有三个文件： BUILD看着应该是用来做构建用的，这不是我这次学习的重点，先跳过。 saga-admin-test.toml 我打开看了一眼，是一个配置文件，从名字可以看出应该是测试用的配置项，后面还会碰到。 main.go 如果不出意外，这个应该就是程序入口了，运气还不错，第二个目录就找到了入口。 接下来详细的看看main.go做了些什么事情： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/*这里我忽略了一些包导入，以及一些常量因为如果每个导入的包都要看的话，会越陷越深。*/func main() { //解析命令行参数 flag.Parse() //初始化配置 if err := conf.Init(); err != nil { log.Error(&quot;conf.Init() error(%v)&quot;, err) panic(err) } //初始化Log log.Init(conf.Conf.Log) defer log.Close() log.Info(&quot;saga-admin start&quot;) //启动一个服务 s := service.New() http.Init(s) //启动一个grpc服务 grpcsvr, err := grpc.New(nil, s.Wechat()) if err != nil { panic(err) } //创建一个长度为1的os.Signal类型的channel c := make(chan os.Signal, 1) //通知 signal.Notify(c, syscall.SIGHUP, syscall.SIGQUIT, syscall.SIGTERM, syscall.SIGINT) for { //从前面创建的channel中读取signal si := &lt;-c log.Info(&quot;saga-admin get a signal %s&quot;, si.String()) switch si { //如果是SIGQUIT、SIGTERM、SIGINT则关闭相关服务，然后退出 case syscall.SIGQUIT, syscall.SIGTERM, syscall.SIGINT: grpcsvr.Shutdown(context.Background()) log.Info(&quot;saga-admin exit&quot;) s.Close() time.Sleep(_durationForClosingServer * time.Second) return case syscall.SIGHUP: default: return } }} 粗略的看了一下代码后，带着疑问，一行一行的来分析，首先第一行： 1flag.Parse() 作为Golang小白，我知道这个应该是使用在flag.StringVar这样的代码后面，定义需要获取的命令行参数。 但是flag.Parse()作为第一行代码前面并没有flag.StringVar类似这样的代码呀，然后我想到了Golang中init函数的作用。于是我开始找main.go中导入的其他包中有没有定义init函数，果不其然，在saga/conf/conf.go中我找到了： 123456func init() { //定义一个命令行参数，用来接收配置文件路径 flag.StringVar(&amp;confPath, &quot;conf&quot;, &quot;&quot;, &quot;config path&quot;) //这个reload后面再讲 reload = make(chan bool, 10)} 回到main.go来看下面几行代码： 1234if err := conf.Init(); err != nil { log.Error(&quot;conf.Init() error(%v)&quot;, err) panic(err)} 忽略错误判断以及日志打印，我们可以看到这几行中最关键的代码就是conf.Init()，这个代码做了些什么事情呢？接下来进入saga/conf/conf.go： 1234567891011121314func Init() (err error) { //判断如果配置文件的路径为空，则执行configCenter()方法 if confPath == &quot;&quot; { return configCenter() } //如果配置文件路径不为空通过toml.DecodeFile(confPath, &amp;Conf)解析配置到&amp;Conf中 if _, err = toml.DecodeFile(confPath, &amp;Conf); err != nil { log.Error(&quot;toml.DecodeFile(%s) err(%+v)&quot;, confPath, err) return } //单独解析TeamInfo相关配置 Conf = parseTeamInfo(Conf) return} 首先看： 123if confPath == &quot;&quot; { return configCenter()} 从函数名可以看出，当没有手动指定配置文件路径是，走配置中心解析配置。configCenter我们先放一放，我们接着往下看： 1234if _, err = toml.DecodeFile(confPath, &amp;Conf); err != nil { log.Error(&quot;toml.DecodeFile(%s) err(%+v)&quot;, confPath, err) return} 跟之前一样，我们忽略错误和日志处理，可以看到这几行关键代码是toml.DecodeFile(confPath, &amp;Conf)， toml这个看着是不是很眼熟，之前在cmd包下我们看到过一个这个格式的文件saga-admin-test.toml，这是一个由GitHub联合创始人Tom Preston-Werner 搞出的极简配置文件格式。各个语言都有相关实现，BZ这里使用的是github.com/BurntSushi/toml这个库。 总而言之，这几行代码无非就是解析配置文件。 继续往下看: 1Conf = parseTeamInfo(Conf) 单独用了一个方法来解析TeamInfo说明toml标准的DecodeFile解析不了，我们来看看这个方法做了什么事情： 123456789101112131415161718192021222324252627282930313233343536/*这个方法做的事情比较简单，直接采用注释的方法讲解*/func parseTeamInfo(c *Config) *Config { /* strings.Fields，我们都知道这个是根据字符串中的空格或者一些个特殊符号来拆分字符串为Array的方法。 我们来看看之前提到的saga-admin-test.toml中c.Property.Department 定义的是什么： [property.department] label = &quot;主站 直播 bplus 开放平台 创作中心 商业产品 数据中心 视频云 游戏 火鸟&quot; value = &quot;mainsite live bplus openplatform creative advertising datacenter videocloud game firebird&quot; */ DeLabel := strings.Fields(c.Property.Department.Label) DeValue := strings.Fields(c.Property.Department.Value) for i := 0; i &lt; len(DeLabel); i++ { /* 所以这几行代码，很显而易见了，就是将上述的label 和value组合成key-value的形式然后append到另外一个(DeInfo)Array中 */ info := &amp;model.PairKey{ Label: DeLabel[i], Value: DeValue[i], } c.Property.DeInfo = append(c.Property.DeInfo, info) } //下面几行代码同上，就不在赘述 buLabel := strings.Fields(c.Property.Business.Label) buValue := strings.Fields(c.Property.Business.Value) for i := 0; i &lt; len(buLabel); i++ { info := &amp;model.PairKey{ Label: buLabel[i], Value: buValue[i], } c.Property.BuInfo = append(c.Property.BuInfo, info) } return c} 话说，上面的Business和Department处理过程一样，为啥不将这个过程提取成一个函数呢？来自小白的疑问。 还记得我们之前跳过一个函数configCenter()吗？接下来我们一起来看看： 1234567891011121314151617181920212223242526func configCenter() (err error) { //这里的conf应该是BZ一个公共组件，这里做的就是创建一个配置中心的client if client, err = conf.New(); err != nil { panic(err) } //这里调用了load函数 if err = load(); err != nil { return } //这里应该是添加了一个配置中心的监听 client.WatchAll() //起一个goroute go func() { //获取事件，如果配置中心的配置存在修改重新调用load函数 for range client.Event() { log.Info(&quot;config reload&quot;) if load() != nil { log.Error(&quot;config reload error (%v)&quot;, err) } else { //load成功往reload chan写入一个数据，这里有个疑问，等后面再说 reload &lt;- true } } }() return} 忽略其它代码，可以看到上面实现配置中心配置加载的应该是load函数： 123456789101112131415161718192021func load() (err error) { //定义一组局部变量 var ( s string ok bool tmpConf *Config ) //通过配置中心的client获取配置，这里的_configkey是常量：&quot;saga-admin.toml&quot; if s, ok = client.Value(_configKey); !ok { err = errors.Errorf(&quot;load config center error [%s]&quot;, _configKey) return } //跟之前一样通过toml解析配置 if _, err = toml.Decode(s, &amp;tmpConf); err != nil { err = errors.Wrapf(err, &quot;could not decode config err(%+v)&quot;, err) return } //跟之前一样单独解析TeamInfo Conf = parseTeamInfo(tmpConf) return} 到这里我们差不多刚刚看完main.go中conf.Init()的调用，接下来回到main.go，继续往下看： 我们跳过Log的初始化，直接看： 1234//调用/saga/service中的New函数s := service.New()//调用/saga/http中的Init函数http.Init(s) 跳转到New函数中，我们看看做了些什么： 1234567891011121314151617181920212223242526272829303132333435func New() (s *Service) { var ( err error ) s = &amp;Service{ dao: dao.New(), cron: cron.New(), } if err = s.cron.AddFunc(conf.Conf.Property.SyncProject.CheckCron, s.collectprojectproc); err != nil { panic(err) } if err = s.cron.AddFunc(conf.Conf.Property.Git.CheckCron, s.alertProjectPipelineProc); err != nil { panic(err) } if err = s.cron.AddFunc(conf.Conf.Property.SyncData.CheckCron, s.syncdataproc); err != nil { panic(err) } if err = s.cron.AddFunc(conf.Conf.Property.SyncData.CheckCronAll, s.syncalldataproc); err != nil { panic(err) } if err = s.cron.AddFunc(conf.Conf.Property.SyncData.CheckCronWeek, s.syncweekdataproc); err != nil { panic(err) } s.cron.Start() // init gitlab client s.gitlab = gitlab.New(conf.Conf.Property.Gitlab.API, conf.Conf.Property.Gitlab.Token) // init online gitlab client s.git = gitlab.New(conf.Conf.Property.Git.API, conf.Conf.Property.Git.Token) // init wechat client s.wechat = wechat.New(s.dao) return} 上面代码大部分都是在做定时任务的创建，cron使用的是&quot;github.com/robfig/cron&quot;这个库，我们挑一个看看： 123if err = s.cron.AddFunc(conf.Conf.Property.SyncProject.CheckCron, s.collectprojectproc); err != nil { panic(err)} conf.Conf.Property.SyncProject.CheckCron 是配置中的cron表达式，在saga-admin-test.toml中看到是 * */15 * * * ? 也就是说这个任务每15分钟执行一次。 s.collectprojectproc 是要执行的任务，接下来看看这个任务做了什么事情： 123456789101112131415161718192021222324252627282930313233343536373839404142func (s *Service) collectprojectproc() { var err error //可以看到实际调用的是CollectProject，这里的context.TODO()表示context还未实现，这里仅仅用作占位，没有实际意义 if err = s.CollectProject(context.TODO()); err != nil { log.Error(&quot;s.CollectProject err (%+v)&quot;, err) }}func (s *Service) CollectProject(c context.Context) (err error) { //这是一组局部变量 var ( projects []*gitlab.Project total = 0 page = 1 ) log.Info(&quot;Collect Project start&quot;) //这里出现了一个magic number，1000 for page &lt;= 1000 { //调用gitlab接口获取指定页码的项目列表，这里的s.gitlab是在service.New()中实例化的。这里有一个疑问。 if projects, err = s.gitlab.ListProjects(page); err != nil { return } num := len(projects) if num &lt;= 0 { break } total = total + num //将获取到的项目保存到db中，这个insertDB就不展开讲了，这里面做的大概就是saveOrUpdate的事情。 for _, p := range projects { if err = s.insertDB(p); err != nil { return } } page = page + 1 } log.Info(&quot;Collect Project end, find %d projects&quot;, total) return} 在service.New()中其他的cron也差不多是做着类似的事情，由于太多，就不在这里一一展开。刚刚说到 s.gitlab.ListProjects(page);我有一个疑问，是什么呢？我们看这里： 12345678s.cron.Start()// init gitlab clients.gitlab = gitlab.New(conf.Conf.Property.Gitlab.API, conf.Conf.Property.Gitlab.Token)// init online gitlab clients.git = gitlab.New(conf.Conf.Property.Git.API, conf.Conf.Property.Git.Token)// init wechat clients.wechat = wechat.New(s.dao) 可以发现cron的start是在gitlab、git、wechat实例化之前，而cron相关的任务中又依赖了这些client，那有没有这么一种可能：这个程序启动的时候正好碰上cron触发，而gitlab，wechat这些client还没有实例化，所以有没有可能出现panic？当然了，这个可能性很小。 让我们再次回到main.go中： 12//初始化一个http服务http.Init(s) 进入Init: 123456789101112131415// Init initfunc Init(s *service.Service) { //这个srv很重要，这是在上面service.New()最后返回的实例，在后面经常用到 srv = s //这个permit是go-common/library/net/http/blademaster 中的组件，应该是用来做接口认证的 authSvc = permit.New2(nil) //下面就是启动http engine了，这个engine就是上面提到的这个blademaster engine := bm.DefaultServer(conf.Conf.BM) engine.Ping(ping) initRouter(engine) if err := engine.Start(); err != nil { log.Error(&quot;engine.Start error(%v)&quot;, err) panic(err) }} 由于这个http服务是依赖的BZ公共的组件，就不继续深入了，我怕出不来了。我们看看initRouter中定义的Router，由于太长，我只选择开始一段： 123456789version := e.Group(&quot;/ep/admin/saga/v1&quot;, authSvc.Permit2(&quot;&quot;)) { project := version.Group(&quot;/projects&quot;) { project.GET(&quot;/favorite&quot;, favoriteProjects) project.POST(&quot;/favorite/edit&quot;, editFavorite) project.GET(&quot;/common&quot;, queryCommonProjects) }... 这就是很常见的url-mapping了，这里的favoriteProjects、editFavorite、queryCommonProjects 都是定义在当前http包下的函数，我们选择favoriteProjects看下： 12345678910111213141516171819func favoriteProjects(ctx *bm.Context) { var ( req = &amp;model.Pagination{} err error userName string ) //这里应该是解析请求参数到req变量中 if err = ctx.Bind(req); err != nil { ctx.JSON(nil, err) return } //这里是调用函数获取当前用户名 if userName, err = getUsername(ctx); err != nil { ctx.JSON(nil, err) return } //我们看到这里最终回到了srv上，调用了实际的处理方法。这里的FavoriteProjects实际就是通过db查询当前用户收藏的项目，我们就不继续深入了。 ctx.JSON(srv.FavoriteProjects(ctx, req, userName))} 上面的流程大概是这样的，首先在http包中将参数等一些信息进行解析，最后调用到了service中的方法。这个就很像Java中流行的写法：从Controller到Service，符合MVC分层的思想。 最后还有一个grpc，我大概看了下，应该是用来企业微信发消息的。 总结： 这应该是用来做gitlab ci告警之类的project，可以看到这个project层次很分明，代码看过去一目了然。 最后，之前还有一个疑问，就是reload这个变量，在初始化时是有长度的： 1reload = make(chan bool, 10) 长度为10，在每次配置文件修改后，goroute watch到event之后会往这个channel写入一个true，但是看完整个代码之后，并没有看到有地方从这个channel取出数据（也有可能是我漏看了），也就是说当修改10次之后，这个地方： 1reload &lt;- true 就会阻塞，从而导致这个goroute无响应？ 码字不易，且转且珍惜。","link":"/archives/f11de5dd.html"},{"title":"Python中的一些语法糖","text":"三元运算符 1c = a if a&gt;b else b 在Java中的写法为： 1c = a&gt;b ? a : b 而Golang则是不支持 循环 Python中常用的while、for Java中支持while、do…while、for、foreach Golang 万能的for，for range in ​ 语句 Python还支持循环else，while …else 、for …else ,表示循环正常结束后执行的代码块。 切片(slice) 123str1 = &quot;abcdefg&quot;print(str1[0])print(str1[0:3]) Golang类似，Java中没有切片的概念 复制运算 12345print('a'*5) # aaaaab = [1]print(b*5) # [1, 1, 1, 1, 1]复制运算不支持字典dict","link":"/archives/d5c5a3fa.html"},{"title":"Python实现图像文字识别","text":"使用的实际是tesseract这个OCR引擎。如果识别的有中文，需要添加中文的chi_sim.traineddata。 我这里使用的是windows，下载是Windows Installer made with MinGW-w64，在安装过程中注意有个选项，展开可以看到各种语言的数据，勾上chi_sim.traineddata即可。 我这里使用的是Python3.7，首先安装必备的依赖 12pip install pytesseractpip install pillow 我使用的Pycharm，直接Alt+Enter导入。 完整的代码如下： 123456import pytesseractfrom PIL import Imageimage = Image.open(&quot;../pic/c.png&quot;)code = pytesseract.image_to_string(image,lang=&quot;chi_sim&quot;,config=&quot;-psm 6&quot;)print(code) 直接运行可能会报错，会提示tesseract识别不了，我看到其他人都是直接修改pytesseract源文件 1tesseract_cmd = 'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe' 我这里的做法是将C:\\Program Files (x86)\\Tesseract-OCR\\添加到环境变量PATH中。 有可能不会生效，需要重启Pycharm。 OCR识别不是100%准确，我这里测试的结果是，可能会多或者少一些字符。 参考资料： https://blog.csdn.net/github_33304260/article/details/79155154","link":"/archives/99680cca.html"},{"title":"区块链、比特币学习笔记","text":"学习区块链、比特币需要先搞明白hash、非对称加密、BASE64/58。比特币中一个重要的概念就是UTXO（未花费输出），你有多少个比特币就是根据这个得来的。 挖矿得来的比特币称为coinbase，这个也是会产生一笔交易的，但是这个交易没有输入，只有输出。比特币会产生分叉，有可能是临时分叉，因为两个人同时计算出了Nonce，同时打包了区块，这时就要看哪一个链条增长的更长，当超过6个区块时，另外一个区块就作废，所有的交易就失效。所以别人给你转比特币时，需要等待至少6个区块的确认，否者你会人财两空。比特币也会产生硬分叉，就是同时存在两个链条，这个与临时分叉不同，这两个分叉谁也不能干掉谁，比如新的分叉BCC，BCH。产生硬分叉的原因其实是人为的，因为现在维护比特币的是core 团队，core团队提出的一些意见（隔离见证、闪电网络），得不到旷工团队的认可，或者说是利益问题。于是就产生了结构不同的区块，这样就分叉了。挖矿（pow）的过程其实是计算一道题:目标值=最大目标值/难度值 通过调整难度值来调整目标值的计算难度 需用通过hash运算，以及随机改变的Nonce来计算出一个hash值，使这个值小于目标值。","link":"/archives/df4f5590.html"},{"title":"比特币、区块链、挖矿是什么","text":"比特币跟人民币美元不一样， 不是银行卡里的一个数字。而是通过比特币账本追溯而来。 你去查询银行卡余额，ATM上很可能显示：余额5元。而要看比特币余额，需要翻开比特币账本：张三转给李四5个比特币，李四转给王五3个比特币，王五转给你1个比特币，于是你有1个比特币。 银行卡里的余额是否可信完全取决于你对银行的信任。比特币余额是经过追溯每次加解密交易而得来，具有极高的可信度。 转账信息采用非对称加密（公钥、私钥），每次转账的信息大概包含如下信息（以李四向王五转账为例）：李四的信息摘要被私钥加密后的产物、王五的公钥、转账金额、账单编号、转账金额来源的账单编号 为什么要包含以上信息呢？是保证了交易的可追溯性和真实性。通过来源的账单编号，可以找到李四的公钥（张三向李四转账）然后验证：（交易信息）——&gt;（交易信息摘要）——&gt;（李四私钥加密后的摘要结果） 1.(李四公钥解密私钥加密后的摘要结果) 得到交易信息摘要 2.（交易信息）——&gt;（交易信息摘要）对比解密结果王五的公钥对应的私钥只有他自己知晓。所以不用担心别人获取这笔转账金额。（下次王五转账给你时，他也需要带上他的私钥加密后的摘要结果才能验证通过，然后才能使用这笔钱 转账一般通过比特币钱包完成，所有装有比特币钱包的设备，都可以收到这笔转账信息，都纷纷开始记录，但是只有一个设备能记录成功（Pow），能成功记录这笔转账信息，就会获得比特币的奖励。这个过程称为挖矿。这也是比特币的来源（与人民币是央行发行的不同）。 什么情况下才算成功记录呢（Pow）？这一笔笔的转账记录，需要存储起来，存到哪里呢？回答是区块中。区块就是一个包含了多笔转账记录的容器。每个区块都有一个自己的标志(HASH)，以及前一个区块的标志(HASH)。这里的HASH是通过一个极其难的计算得来（通过账单信息以及一个Nonce得到一个符合设定规则的HASH）。区块可以形象的理解为一个纸质账本的一页。前一个区块可以理解为前一页。这一块一块的连起来就是区块链（账本）。 个人浅显的理解，可能存在错误的地方。","link":"/archives/838301b8.html"},{"title":"AbstractQueuedSynchronizer-随记","text":"常见误区：Lock（乐观锁，自旋锁）一定比Synchronized好。这个说法是不正确的。自旋锁适合锁竞争不是很激烈的情况下使用，因为其使用了死循环，比较消耗CPU资源。Synchronized在JDK1.5后进行了优化，通过锁升级(偏向锁-&gt;轻量级锁(通常是自旋)-&gt;重量级锁) 提升了性能。","link":"/archives/5e0e6b4c.html"},{"title":"CAP个人浅显的理解","text":"分布式系统为了保证数据不丢失，于是我们将数据做了多个副本放在了不同的服务器上【Partition tolerance(分区耐受性)： 可靠性）】，并且保持更新多个副本，但是在更新副本的时候，可能由于网络等诸多原因导致其中一个或多个副本无法更新，此时就面临了一个选择：更新剩下的副本？or 都不更新了？选择更新剩下的副本，则是选择了【Availability(可用性)： 好的响应性能】，此类型系统保证了AP。选择都不更新了，则是选择了【Consistency(一致性)： 数据一致更新】，此类型系统保证了CP。 以上为个人片面且浅显的理解。","link":"/archives/e8ec77e1.html"},{"title":"CountDownLatch-注意事项","text":"先看一段代码： 1234567891011121314CountDownLatch countDownLatch = new CountDownLatch(params.size()); try { params.forEach(regionNameMapping -&gt; { CompletableFuture.runAsync(() -&gt; { Region region = this.getRegionById(regionNameMapping.getRegionId()); regionNameMapping.getRegionNameConsumer().accept(region.getName()); countDownLatch.countDown(); }); }); countDownLatch.await(); } catch (Exception e) { log.error(e.getMessage(), e); } 上面的代码逻辑很简单，并发去执行getRegionById这个方法。然后await等待结果。但是里面有一个隐患，当region查出来为null时，会出现NPE，就会导致countDown()无法被执行，于是程序就一直阻塞在 12countDownLatch.await(); 正确的写法： 12345678910111213141516CountDownLatch countDownLatch = new CountDownLatch(params.size()); try { params.forEach(regionNameMapping -&gt; { CompletableFuture.runAsync(() -&gt; { try{ Region region = this.getRegionById(regionNameMapping.getRegionId()); regionNameMapping.getRegionNameConsumer().accept(region.getName()); }finally{ countDownLatch.countDown(); } }); }); countDownLatch.await(3,TimeUnit.SECONDS); } catch (Exception e) { log.error(e.getMessage(), e); } 添加try、finally，保证最终锁会被释放，以及设置等待超时时间，避免程序挂掉。 所有使用AbstractQueuedSynchronizer实现的同步器，例如Lock，Semaphore、等都应该如此。","link":"/archives/20c5f4b2.html"},{"title":"HashMap和ConcurrentHashMap中的initialCapacity","text":"HashMap 默认有一个初始大小（initialCapacity），这个初始大小是16。在各种开发规范手册中都可以看到会建议设置这个大小。例如：new HashMap(3);那么我们设置了初始容量为3，HashMap的容量真的会初始化为3了吗？答案是否定的。为了提高Hash效率，Java中会重新计算这个值，获得一个&gt;3的最小2的N次方，大于3的最小2的N次方就是4(关于为什么请参照https://www.zhihu.com/question/28562088/answer/111668116)。这个4是怎么来的呢？ 1234567int n = cap - 1; n |= n &gt;&gt;&gt; 1;n |= n &gt;&gt;&gt; 2;n |= n &gt;&gt;&gt; 4;n |= n &gt;&gt;&gt; 8;n |= n &gt;&gt;&gt; 16;return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; 嗯哼？第一眼看到觉得莫名奇妙，仔细看看，就会很佩服了！这里主要用到了两个运算，位移运算（向右无符号，高位补零）和或运算。例如：cap=3，套入上面的公式，如下： 1234int n = 3-1;//第一步位移运算转换为二进制为：10&gt;&gt;&gt;1 = 01//第二部或运算转换为二进制为：10|=01 = 11n|=n&gt;&gt;&gt;1; 最终n=11（二进制）最后加上1 = 100（二进制）转换成10进制就是4啦！需要注意的是：cap-1，这是因为，如果cap本身就是2的次方，套用上面的公式得出来的结果就不是最小的2的n次方了。 下面来说ConcurrentHashMap中的最小2的n次方技巧。应该都知道ConcurrentHashMap是通过分段锁来提高效率的，其中一个segment就是一个锁。但是初始化的时候初始segment数组多大合适呢？segment大小跟concurrencyLevel有关，求的是大于concurencyLevel的最小2的n次方。 12345 int ssize = 1; while (ssize &lt; concurrencyLevel) { ++ sshift; ssize &lt;&lt;= 1; } 这里用到的是位移运算（向左）。例如concurrencyLevel=5，第一次ssize&lt;&lt;=1 结果：10（二进制），2（10进制）第二次ssize&lt;&lt;=1 结果：100（二进制），4（10进制）第三次ssize&lt;&lt;=1 结果：1000（二进制），8（10进制）这时结果已经&gt;concurrencyLevel，while结束，于是最终结果就是8.所以最终segment 数组大小会被初始化为8.","link":"/archives/5536c54e.html"},{"title":"Java 导出PDF","text":"废话少说，直接上代码： Maven: 12345&lt;dependency&gt; &lt;groupId&gt;org.xhtmlrenderer&lt;/groupId&gt; &lt;artifactId&gt;flying-saucer-pdf-itext5&lt;/artifactId&gt; &lt;version&gt;9.1.5&lt;/version&gt; &lt;/dependency&gt; Java: 123456789101112131415OutputStream os = null; try { os = new FileOutputStream(outputFile); ITextRenderer renderer = new ITextRenderer(); ITextFontResolver fontResolver = renderer.getFontResolver(); //中文问题解决，将字体文件simsun.ttc 放到resources\\fonts 目录下 fontResolver.addFont(App.class.getClassLoader().getResource(&quot;fonts\\\\simsun.ttc&quot;).toURI().toString(), BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED);String htmlStr=&quot;这里是freemarker模板引擎解析出来的html代码&quot;; renderer.setDocumentFromString(htmlStr);// 图片显示问题解决，html代码中img src 用相对路径 renderer.getSharedContext().setBaseURL(App.class.getClassLoader().getResource(&quot;&quot;).toURI().toString()); renderer.layout(); renderer.createPDF(os); //完成创建，自动关闭Document资源 renderer.finishPDF();","link":"/archives/30af2543.html"},{"title":"IDEA-Scratches的一个问题","text":"新建一个scratch，编写如下代码： 12List&lt;String&gt; list = Arrays.asList(&quot;11 22&quot;,&quot;22 11&quot;,&quot;32 44&quot;); list.stream().map(item-&gt;item.split(&quot; &quot;)).flatMap(Arrays::stream).distinct().collect(Collectors.toList()).forEach(System.out::println); 其中Arrays::stream，编译错误，提示Cannot resolve method ‘stream’在工程中编写则无此错误。 IDEA版本：2018.3.2 UE版JDK：jdk1.8.0_121","link":"/archives/241ed4e3.html"},{"title":"Maven Settings 中的一些容易混淆的概念","text":"首先是repositories，其中定义了一些远程仓库（私服）。本来是可以直接定义在POM.xml ，但是由于一个公司通常多个项目都是使用的同一个远程仓库（私服）。为了每个项目不重复定义。所以可以统一配置在settings.xml。由于settings下不能直接定义repositories所以采用了profiles。同时也可以使用profiles做不同环境下的配置切换。 容易混淆的是mirrors，配置多个mirror，并不是每一个都会生效，始终只有第一个有用。另外mirrors 跟profiles没有什么直接关系，有关系的是repository，mirrorOf 中配置的是repository id（支持表达式）。一般我们mirror的都是central这类官方，因为mirror的主要作用就是解决不同网络环境下，这种官方的或者第三方的仓库速度问题。如果你有私服，然后直接mirrorOf * 到了阿里云的镜像库，那么你私服的Jar可能就访问不到了。 maven找Jar的路径大概是，本地仓库&gt;各个远程库，如果配置了镜像，则走镜像库。","link":"/archives/fb1fa3ca.html"},{"title":"Lambda应用与浅析","text":"引入在Java8之前创建一个线程的写法（之一）： 123456789101112131415161718192021public class LambdaTest { public static void main(String[] args) { new Thread(new Runnable() { @Override public void run() { System.out.println(&quot;hello inner class!&quot;); } }); }} 通过查看编译后的生成的Class文件，可以得知new Runnable这块会生成一个匿名类： 文件内容如下： 123456789101112131415final class LambdaTest$1 implements Runnable { LambdaTest$1() { } public void run() { System.out.println(&quot;hello inner class!&quot;); }} 在Java8开始一切都开始变得不同，可以这样写： 1234567891011public class LambdaTest { public static void main(String[] args) { new Thread(()-&gt;System.out.println(&quot;hello inner class!&quot;)); }} 其中()-&gt;System.out.println(&quot;hello inner class!&quot;)就是今天的主角lambda表达式! 简介Lambda表达式，是一种匿名函数，一开始只有函数式编程语言中有此功能，但是现在已经有越来越多的命令式编程语言中也支持了Lambda表达式。 Lambda表达式不是一个新鲜事，最早支持Lambda表达式的是1958发布的LISP语言。在Java中也存在了快7-8年时间（2014年发布的Java8开始支持），目前Java已经都发布16。 Lambda表达式简化匿名内部类的书写，但Lambda表达式并不能取代所有的匿名内部类，只能用来取代函数接口（Functional Interface）的简写。 说到函数接口，那么来看下什么是函数接口，看看最开始的例子里出现的Runnable ： 123456789@FunctionalInterfacepublic interface Runnable { public abstract void run();} 再看看另外一个Comparable : 1234567public interface Comparable&lt;T&gt; { public int compareTo(T o);} 发现了什么？只有一个[抽象]方法的接口即是函数接口。 @FunctionalInterface 并不是必须的，加上此注解可以让编译器帮你check当前定义的是不是正确的函数接口： Java8 引入Lambda表达式的同时也定义了很多新的函数接口，适用于大部分场景： 也就是说Java8中的Lambda表达式不可以随意乱写，必须有与其对应的函数接口定义，例如： 1(a, b) -&gt; a + b; 如果在JDK中找不到对应的函数接口，我们可以自定义一个： 1234567@FunctionalInterfacepublic interface TwoParamsOneResultFunction { Integer get(Integer p1, Integer p2);} 应用下面来通过一个实例看看Lambda表达式的应用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859private static boolean sync2Es(List&lt;Long&gt; result, EsIndexEnum esIndexEnum, boolean isAsync) { log.info(&quot;同步{}至ES，idList:{},isAsync:{}&quot;, JSON.toJSONString(esIndexEnum), JSON.toJSONString(result), isAsync); if (esIndexEnum == null) { return false; } if (CollectionUtils.isEmpty(result)) { return true; } //es最多支持一次同步3000条，所以需要拆分 List&lt;List&lt;Long&gt;&gt; partition = Lists.partition(StreamUtils.safeList(result), AssetsConstant.MAX_BATCH_SYNC_SIZE); //es支持同步和异步，按需选择 EsSyncProcessorInstance instance = EsSyncProcessorFactory.getInstance(esIndexEnum.getIndexClass()); BiFunction&lt;EsSyncProcessorInstance, List&lt;Long&gt;, EsResult&lt;BulkMessage&gt;&gt; esFunction = getEsSyncFunction(isAsync); boolean esResult = StreamUtils.allMatch(StreamUtils.listToList(partition, ids -&gt; { EsResult&lt;BulkMessage&gt; bulkMessageEsResult = esFunction.apply(instance, ids); //es可能失败，重试一次，如果还是不行那估计就是大问题了。 if (!bulkMessageEsResult.isSuccess()) { log.error(&quot;同步ES失败:{},重试一次&quot;, JSON.toJSONString(bulkMessageEsResult)); bulkMessageEsResult = esFunction.apply(instance, StreamUtils.listToList(StreamUtils.safeGetField(bulkMessageEsResult.getValue(), BulkMessage::getFailIds), Long::valueOf)); if (!bulkMessageEsResult.isSuccess()) { log.error(&quot;同步ES重试再次失败:{}&quot;, JSON.toJSONString(bulkMessageEsResult)); } } return bulkMessageEsResult.isSuccess(); }), Boolean::booleanValue); if (!esResult) { log.error(&quot;同步到ES存在失败:{}&quot;, JSON.toJSONString(result)); } return esResult;} 上面这一段代码主要是在做同步数据给ES的逻辑，由于ES提供了多种同步方式，不想将细节暴露给上层，所以做了一些封装。 先看看这一段： 1BiFunction&lt;EsSyncProcessorInstance, List&lt;Long&gt;, EsResult&lt;BulkMessage&gt;&gt; esFunction = getEsSyncFunction(isAsync); 调用了： 12345private static BiFunction&lt;EsSyncProcessorInstance, List&lt;Long&gt;, EsResult&lt;BulkMessage&gt;&gt; getEsSyncFunction(boolean isAsync) { return isAsync ? EsSyncProcessorInstance::syncByPrimaryKey : EsSyncProcessorInstance::syncByPrimaryKeyImmediate;} 其中可以看到类似EsSyncProcessorInstance::syncByPrimaryKey这种写法，这个叫方法引用，可以理解为是一种特殊的lambda表达式（语法糖），相当于给一段函数取了一个名字，然后直接引用，看看syncByPrimaryKey： 123456789101112131415161718192021public EsResult&lt;BulkMessage&gt; syncByPrimaryKey(List&lt;Long&gt; indexPrimaryKeyList) { String method = &quot;EsSyncProcessorInstance#syncByPrimaryKey&quot;; if (indexPrimaryKeyList != null &amp;&amp; indexPrimaryKeyList.size() &gt; 3000) { log.warn(&quot;{} allowable size exceeded, size={}, max={}&quot;, new Object[]{method, indexPrimaryKeyList.size(), 3000}); return null; } else { EsSyncLoopQuery query = this.newInstanceQuery(); query.setIdList(indexPrimaryKeyList); return this.synchronizeToEs(query, this.defaultConfig()); }} 需要一个List 参数，一个EsResult返回值，那为什么适配的函数接口是BiFunction？看看BiFunction： 12345678910111213@FunctionalInterfacepublic interface BiFunction&lt;T, U, R&gt; {//这里需要两个参数 R apply(T t, U u); ...} 由于syncByPrimaryKey是一个实例方法，所以还需要一个实例对象才能调用，所以EsSyncProcessorInstance::syncByPrimaryKey 相当于(EsSyncProcessorInstance instance,List&lt;Long&gt; ids)-&gt;{...} 再一次验证，lambda表达式不能随意乱写，必须有对应的函数接口对应。 接下来再来看看： 1StreamUtils.listToList(partition, ids -&gt; { 这是对Java8 Stream+Lambda的一层封装： 12345public static &lt;T, R&gt; List&lt;R&gt; listToList(List&lt;T&gt; list, Function&lt;T, R&gt; function) { return safeList(list).stream().map(function).filter(Objects::nonNull).collect(Collectors.toList());} 可以看到stream().map需要一个function用来转换数据，而其他的基本都是固定写法，这体现了Lambda的另外一个好处：抽象行为。 还有很多用法不一一介绍了。 原理这么🐂🍺的Lambda表达式Java底层是怎么实现的呢？首先可以确定的是，不是匿名内部类，还是最开始的例子，我们改成lambda表达式后编译看看： 1234567891011public class LambdaTest { public static void main(String[] args) { new Thread(()-&gt;System.out.println(&quot;hello lambda&quot;)); }} 可以看到并没有匿名内部类生成，我们查看下LambdaTest.class字节码(javap -c -p -v LambdaTest.class)： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225Classfile /Users/zhaojingzhou/workspace/larry/lambda/src/LambdaTest.class Last modified 2021-8-2; size 1047 bytes MD5 checksum 191cb67c3e5a457eb20b4c8a47f5a5d2 Compiled from &quot;LambdaTest.java&quot;public class LambdaTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #9.#19 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Class #20 // java/lang/Thread #3 = InvokeDynamic #0:#25 // #0:run:()Ljava/lang/Runnable; #4 = Methodref #2.#26 // java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V #5 = Fieldref #27.#28 // java/lang/System.out:Ljava/io/PrintStream; #6 = String #29 // hello inner class! #7 = Methodref #30.#31 // java/io/PrintStream.println:(Ljava/lang/String;)V #8 = Class #32 // LambdaTest #9 = Class #33 // java/lang/Object #10 = Utf8 &lt;init&gt; #11 = Utf8 ()V #12 = Utf8 Code #13 = Utf8 LineNumberTable #14 = Utf8 main #15 = Utf8 ([Ljava/lang/String;)V #16 = Utf8 lambda$main$0 #17 = Utf8 SourceFile #18 = Utf8 LambdaTest.java #19 = NameAndType #10:#11 // &quot;&lt;init&gt;&quot;:()V #20 = Utf8 java/lang/Thread #21 = Utf8 BootstrapMethods #22 = MethodHandle #6:#34 // invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; #23 = MethodType #11 // ()V #24 = MethodHandle #6:#35 // invokestatic LambdaTest.lambda$main$0:()V #25 = NameAndType #36:#37 // run:()Ljava/lang/Runnable; #26 = NameAndType #10:#38 // &quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V #27 = Class #39 // java/lang/System #28 = NameAndType #40:#41 // out:Ljava/io/PrintStream; #29 = Utf8 hello inner class! #30 = Class #42 // java/io/PrintStream #31 = NameAndType #43:#44 // println:(Ljava/lang/String;)V #32 = Utf8 LambdaTest #33 = Utf8 java/lang/Object #34 = Methodref #45.#46 // java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; #35 = Methodref #8.#47 // LambdaTest.lambda$main$0:()V #36 = Utf8 run #37 = Utf8 ()Ljava/lang/Runnable; #38 = Utf8 (Ljava/lang/Runnable;)V #39 = Utf8 java/lang/System #40 = Utf8 out #41 = Utf8 Ljava/io/PrintStream; #42 = Utf8 java/io/PrintStream #43 = Utf8 println #44 = Utf8 (Ljava/lang/String;)V #45 = Class #48 // java/lang/invoke/LambdaMetafactory #46 = NameAndType #49:#53 // metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; #47 = NameAndType #16:#11 // lambda$main$0:()V #48 = Utf8 java/lang/invoke/LambdaMetafactory #49 = Utf8 metafactory #50 = Class #55 // java/lang/invoke/MethodHandles$Lookup #51 = Utf8 Lookup #52 = Utf8 InnerClasses #53 = Utf8 (Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; #54 = Class #56 // java/lang/invoke/MethodHandles #55 = Utf8 java/lang/invoke/MethodHandles$Lookup #56 = Utf8 java/lang/invoke/MethodHandles{ public LambdaTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 9: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=1, args_size=1 0: new #2 // class java/lang/Thread 3: dup 4: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; 9: invokespecial #4 // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V 12: pop 13: return LineNumberTable: line 14: 0 line 19: 13 private static void lambda$main$0(); descriptor: ()V flags: ACC_PRIVATE, ACC_STATIC, ACC_SYNTHETIC Code: stack=2, locals=0, args_size=0 0: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String hello inner class! 5: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 14: 0}SourceFile: &quot;LambdaTest.java&quot;InnerClasses: public static final #51= #50 of #54; //Lookup=class java/lang/invoke/MethodHandles$Lookup of class java/lang/invoke/MethodHandlesBootstrapMethods: 0: #22 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; Method arguments: #23 ()V #24 invokestatic LambdaTest.lambda$main$0:()V #23 ()V 很多信息我们关注一下重点： 14: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; 第85行可以看到原lambda表达式被编译成了invokedynamic 字节码，这个是Java中多个调用字节码之一，其它的分别是invokestatic、invokevirtual、invokespecial、invokeinterface。也是Java1.0以后第一个被新增的调用字节码。 接下来看#3： 1#3 = InvokeDynamic #0:#25 // #0:run:()Ljava/lang/Runnable; #0: 1234567891011BootstrapMethods: 0: #22 invokestatic java/lang/invoke/LambdaMetafactory.metafactory:(Ljava/lang/invoke/MethodHandles$Lookup;Ljava/lang/String;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodType;Ljava/lang/invoke/MethodHandle;Ljava/lang/invoke/MethodType;)Ljava/lang/invoke/CallSite; Method arguments: #23 ()V #24 invokestatic LambdaTest.lambda$main$0:()V #23 ()V JVM规范规定，如果类的常量池中存在CONSTANT_InvokeDynamic_info的话，那么attributes表中就必定有且仅有一个BootstrapMethods属性。BootstrapMethods属性是个变长的表。 其中根据相关信息会创建一个DynamicCallSite动态调用点，可以看到最终调用的方法为： 12345678910111213141516171819202122invokestatic LambdaTest.lambda$main$0:()V private static void lambda$main$0(); descriptor: ()V flags: ACC_PRIVATE, ACC_STATIC, ACC_SYNTHETIC Code: stack=2, locals=0, args_size=0 0: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String hello inner class! 5: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 14: 0 也就是说Java虽然不会对Lambda表达式生成匿名类，但是会生成匿名静态方法。 引用https://segmentfault.com/a/1190000020607546 https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html https://stackoverflow.com/questions/30733557/what-is-a-bootstrap-method","link":"/archives/d53a1750.html"},{"title":"Mybatis Mapper 源码分析","text":"天天都在用的Mybatis，为啥调用一个Mapper接口就能执行SQL，你有没有想过这个问题？ 这一切都得从 @MapperScan 这个注解开始说起。打开这个注解定义可以看到： 1234@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Import({MapperScannerRegistrar.class}) 上面的元注解中重点关注@Import(MapperScannerRegistrar.class)，这是Spring的一个注解，允许导入@Configuration类、 ImportSelector和ImportBeanDefinitionRegistrar实现。很明显MapperScannerRegistrar.class 应该是ImportBeanDefinitionRegistrar的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { private ResourceLoader resourceLoader; /** * {@inheritDoc} */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { AnnotationAttributes annoAttrs = AnnotationAttributes.fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // this check is needed in Spring 3.1 if (resourceLoader != null) { scanner.setResourceLoader(resourceLoader); } Class&lt;? extends Annotation&gt; annotationClass = annoAttrs.getClass(&quot;annotationClass&quot;); if (!Annotation.class.equals(annotationClass)) { scanner.setAnnotationClass(annotationClass); } Class&lt;?&gt; markerInterface = annoAttrs.getClass(&quot;markerInterface&quot;); if (!Class.class.equals(markerInterface)) { scanner.setMarkerInterface(markerInterface); } Class&lt;? extends BeanNameGenerator&gt; generatorClass = annoAttrs.getClass(&quot;nameGenerator&quot;); if (!BeanNameGenerator.class.equals(generatorClass)) { scanner.setBeanNameGenerator(BeanUtils.instantiateClass(generatorClass)); } Class&lt;? extends MapperFactoryBean&gt; mapperFactoryBeanClass = annoAttrs.getClass(&quot;factoryBean&quot;); if (!MapperFactoryBean.class.equals(mapperFactoryBeanClass)) { scanner.setMapperFactoryBean(BeanUtils.instantiateClass(mapperFactoryBeanClass)); } scanner.setSqlSessionTemplateBeanName(annoAttrs.getString(&quot;sqlSessionTemplateRef&quot;)); scanner.setSqlSessionFactoryBeanName(annoAttrs.getString(&quot;sqlSessionFactoryRef&quot;)); List&lt;String&gt; basePackages = new ArrayList&lt;String&gt;(); for (String pkg : annoAttrs.getStringArray(&quot;value&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (String pkg : annoAttrs.getStringArray(&quot;basePackages&quot;)) { if (StringUtils.hasText(pkg)) { basePackages.add(pkg); } } for (Class&lt;?&gt; clazz : annoAttrs.getClassArray(&quot;basePackageClasses&quot;)) { basePackages.add(ClassUtils.getPackageName(clazz)); } scanner.registerFilters(); scanner.doScan(StringUtils.toStringArray(basePackages)); } /** * {@inheritDoc} */ @Override public void setResourceLoader(ResourceLoader resourceLoader) { this.resourceLoader = resourceLoader; }} 可以看到上面代码在做一件事，就是初始化ClassPathMapperScanner，最后调用了doScan： 12345678910111213public class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner {public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) { logger.warn(&quot;No MyBatis mapper was found in '&quot; + Arrays.toString(basePackages) + &quot;' package. Please check your configuration.&quot;); } else { processBeanDefinitions(beanDefinitions); } return beanDefinitions; } 首先调用了父类的doScan，里面的主要逻辑是查找指定的basePackages下的所有Components，即声明了@Component以及将@Component作为元注解的注解，例如@Repository，感兴趣的可以看看： org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider#findCandidateComponents org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider#isCandidateComponent(org.springframework.core.type.classreading.MetadataReader) org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider#registerDefaultFilters org.springframework.core.type.filter.AnnotationTypeFilter#hasAnnotation org.springframework.core.annotation.AnnotationUtils#getAnnotation(java.lang.reflect.AnnotatedElement, java.lang.Class) 接下来调用了processBeanDefinitions: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) { GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) { definition = (GenericBeanDefinition) holder.getBeanDefinition(); if (logger.isDebugEnabled()) { logger.debug(&quot;Creating MapperFactoryBean with name '&quot; + holder.getBeanName() + &quot;' and '&quot; + definition.getBeanClassName() + &quot;' mapperInterface&quot;); } // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); // issue #59 definition.setBeanClass(this.mapperFactoryBean.getClass()); definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig); boolean explicitFactoryUsed = false; if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) { definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, new RuntimeBeanReference(this.sqlSessionFactoryBeanName)); explicitFactoryUsed = true; } else if (this.sqlSessionFactory != null) { definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, this.sqlSessionFactory); explicitFactoryUsed = true; } if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) { if (explicitFactoryUsed) { logger.warn(&quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;); } definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, new RuntimeBeanReference(this.sqlSessionTemplateBeanName)); explicitFactoryUsed = true; } else if (this.sqlSessionTemplate != null) { if (explicitFactoryUsed) { logger.warn(&quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;); } definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, this.sqlSessionTemplate); explicitFactoryUsed = true; } if (!explicitFactoryUsed) { if (logger.isDebugEnabled()) { logger.debug(&quot;Enabling autowire by type for MapperFactoryBean with name '&quot; + holder.getBeanName() + &quot;'.&quot;); } definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); } } } 重点看看这两行代码： 12definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); definition.setBeanClass(this.mapperFactoryBean.getClass()); 似乎已经可以看出点蛛丝马迹，这里将Mapper的BeanDefinition的BeanClass替换为了this.mapperFactoryBean.getClass(): 1private MapperFactoryBean&lt;?&gt; mapperFactoryBean = new MapperFactoryBean&lt;Object&gt;(); 并且将原本的BeanClass添加为了构造函数参数： 1definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName()); 熟悉Spring的应该都知道，Spring加载完BeanDefinition后会通过BeanClass来去实例化Bean，这里的BeanClass被替换为了一个FactoryBean： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class MapperFactoryBean&lt;T&gt; extends SqlSessionDaoSupport implements FactoryBean&lt;T&gt; { private Class&lt;T&gt; mapperInterface; private boolean addToConfig = true; public MapperFactoryBean() { //intentionally empty } public MapperFactoryBean(Class&lt;T&gt; mapperInterface) { this.mapperInterface = mapperInterface; } /** * {@inheritDoc} */ @Override protected void checkDaoConfig() { super.checkDaoConfig(); notNull(this.mapperInterface, &quot;Property 'mapperInterface' is required&quot;); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) { try { configuration.addMapper(this.mapperInterface); } catch (Exception e) { logger.error(&quot;Error while adding the mapper '&quot; + this.mapperInterface + &quot;' to configuration.&quot;, e); throw new IllegalArgumentException(e); } finally { ErrorContext.instance().reset(); } } } /** * {@inheritDoc} */ @Override public T getObject() throws Exception { return getSqlSession().getMapper(this.mapperInterface); } /** * {@inheritDoc} */ @Override public Class&lt;T&gt; getObjectType() { return this.mapperInterface; } /** * {@inheritDoc} */ @Override public boolean isSingleton() { return true; } //------------- mutators -------------- /** * Sets the mapper interface of the MyBatis mapper * * @param mapperInterface class of the interface */ public void setMapperInterface(Class&lt;T&gt; mapperInterface) { this.mapperInterface = mapperInterface; } /** * Return the mapper interface of the MyBatis mapper * * @return class of the interface */ public Class&lt;T&gt; getMapperInterface() { return mapperInterface; } /** * If addToConfig is false the mapper will not be added to MyBatis. This means * it must have been included in mybatis-config.xml. * &lt;p/&gt; * If it is true, the mapper will be added to MyBatis in the case it is not already * registered. * &lt;p/&gt; * By default addToCofig is true. * * @param addToConfig */ public void setAddToConfig(boolean addToConfig) { this.addToConfig = addToConfig; } /** * Return the flag for addition into MyBatis config. * * @return true if the mapper will be added to MyBatis in the case it is not already * registered. */ public boolean isAddToConfig() { return addToConfig; }} 可以看到之前那个被注册的构造函数参数应该就是在这被使用的： 123 public MapperFactoryBean(Class&lt;T&gt; mapperInterface) { this.mapperInterface = mapperInterface;} Spring 关于这个Bean构造函数的处理： 123456789 org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#autowireConstructor// Need to determine the constructor... Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) { return autowireConstructor(beanName, mbd, ctors, args); } 总之，Spring通过构造函数创建了一个 MapperFactoryBean 对象。接下来Spring去初始化这个Bean，Spring对FactoryBean有特殊处理，实际会调用getObject方法返回具体的Bean。感兴趣的可以看： 1org.springframework.beans.factory.support.FactoryBeanRegistrySupport#doGetObjectFromFactoryBean 这下又回到了MapperFactoryBean中，来看看getObject： 1234567/** * {@inheritDoc} */ @Override public T getObject() throws Exception { return getSqlSession().getMapper(this.mapperInterface); } 调用了父类getSqlSession()方法获得SqlSession，然后调用getMapper，传入了当前实际的Mapper。通过： org.apache.ibatis.session.SqlSessionFactoryBuilder#build(org.apache.ibatis.session.Configuration) org.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSessionFromDataSource 可以知道SqlSession实际的类型应该是DefaultSqlSession，看看getMapper： 1234@Overridepublic &lt;T&gt; T getMapper(Class&lt;T&gt; type) { return configuration.&lt;T&gt;getMapper(type, this);} 又调用了configuration的getMapper，configuration初始化可以看看org.mybatis.spring.SqlSessionFactoryBean#buildSqlSessionFactory，我们写的SQL就是在这个里面被解析的。到这里已经基本很清晰了。接着看： 123456789101112131415161718//configuration中的getMapperpublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { return mapperRegistry.getMapper(type, sqlSession);}//MapperRegistry中的getMapperpublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;); } try { return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e); }} 关键就是 MapperProxyFactory了，这个是在 org.apache.ibatis.binding.MapperRegistry#addMapper 时会为每个Mapper绑定一个。看newInstance： 1234567public T newInstance(SqlSession sqlSession) { final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);} protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); } 也就是说最终Mapper注册到BeanFactory中的是一个代理类MapperProxy，我们知道被代理的方法最终都会被转发到代理类的invoke方法: 1234567891011121314@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } else if (isDefaultMethod(method)) { return invokeDefaultMethod(proxy, method, args); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); } 如果不是Object类的方法，也不是Mapper接口的default（默认）方法，那么调用的是mapperMethod.execute(sqlSession, args): 123456789101112131415161718192021222324252627282930313233343536373839404142434445public Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) { case INSERT: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { result = executeForMany(sqlSession, args); } else if (method.returnsMap()) { result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { result = executeForCursor(sqlSession, args); } else { Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); } break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName()); } if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) { throw new BindingException(&quot;Mapper method '&quot; + command.getName() + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;); } return result; } 到这就差不多了吧？后面已经没啥好说了，基本就是通过statement name找到MappedStatement然后去执行sql了。 另外一个小知识，Mybatis是怎么在插入之后返回自增主键的？答案就在： org.apache.ibatis.executor.statement.PreparedStatementHandler#update org.apache.ibatis.executor.keygen.KeyGenerator#processAfter 写在最后Spring代码实在太难看了，一环套一环，各种递归，必须debug才能看清。","link":"/archives/fb5cf917.html"},{"title":"MySQL 事务查询","text":"查询事务SELECT * FROM information_schema.INNODB_TRX; 查询正在锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 查询等待锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; 查询进程show PROCESSLIST; 查询是否锁表show OPEN TABLES where In_use &gt; 0;","link":"/archives/c1627f94.html"},{"title":"Netty中FastThreadLocal源码解析","text":"简介ThreadLocal一个特殊变体，当从FastThreadLocalThread访问时，可获得更高的访问性能。在内部， FastThreadLocal在数组中使用常量索引来查找变量，而不是使用哈希码和哈希表。 尽管看似非常微妙，但与使用哈希表相比，它在性能上却有一点优势，并且在经常访问时很有用。要利用此线程局部变量，您的线程必须是FastThreadLocalThread或其子类型。 由于这个原因，默认情况下， DefaultThreadFactory创建的所有线程均为FastThreadLocalThread 。请注意，只有在扩展FastThreadLocalThread线程上才可以使用快速路径，因为它需要一个特殊的字段来存储必要的状态。 任何其他类型的线程的访问都回退到常规ThreadLocal 。 上面这段描述来自FastThreadLocal源码中的文档，从中可以知道FastThreadLocal必须和FastThreadLocalThread或其子类型一起使用才可以达到Fast的效果。 FastThreadLocalThread既然必须要和FastThreadLocalThread 一起使用，那就来看看FastThreadLocalThread到底有什么： 123456789101112131415161718192021/** * A special {@link Thread} that provides fast access to {@link FastThreadLocal} variables. * 一种特殊的{@link Thread}，可以快速访问{@link FastThreadLocal}变量。 */public class FastThreadLocalThread extends Thread { // This will be set to true if we have a chance to wrap the Runnable. private final boolean cleanupFastThreadLocals; private InternalThreadLocalMap threadLocalMap; public FastThreadLocalThread() { cleanupFastThreadLocals = false; } public FastThreadLocalThread(Runnable target) { super(FastThreadLocalRunnable.wrap(target)); cleanupFastThreadLocals = true; }…… 省略了一部分代码，可以看到FastThreadLocalThread继承自Thread，额外多了一个InternalThreadLocalMap threadLocalMap，从doc中可以看出这个变量就是关键。 InternalThreadLocalMap1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * The internal data structure that stores the thread-local variables for Netty and all {@link FastThreadLocal}s. * Note that this class is for internal use only and is subject to change at any time. Use {@link FastThreadLocal} * unless you know what you are doing. */public final class InternalThreadLocalMap extends UnpaddedInternalThreadLocalMap { static final ThreadLocal&lt;InternalThreadLocalMap&gt; slowThreadLocalMap = new ThreadLocal&lt;InternalThreadLocalMap&gt;(); static final AtomicInteger nextIndex = new AtomicInteger(); /** Used by {@link FastThreadLocal} */ Object[] indexedVariables; public static final Object UNSET = new Object(); public static InternalThreadLocalMap get() { Thread thread = Thread.currentThread(); if (thread instanceof FastThreadLocalThread) { return fastGet((FastThreadLocalThread) thread); } else { return slowGet(); } } private static InternalThreadLocalMap fastGet(FastThreadLocalThread thread) { InternalThreadLocalMap threadLocalMap = thread.threadLocalMap(); if (threadLocalMap == null) { thread.setThreadLocalMap(threadLocalMap = new InternalThreadLocalMap()); } return threadLocalMap; } private static InternalThreadLocalMap slowGet() { ThreadLocal&lt;InternalThreadLocalMap&gt; slowThreadLocalMap = UnpaddedInternalThreadLocalMap.slowThreadLocalMap; InternalThreadLocalMap ret = slowThreadLocalMap.get(); if (ret == null) { ret = new InternalThreadLocalMap(); slowThreadLocalMap.set(ret); } return ret; } public static int nextVariableIndex() { int index = nextIndex.getAndIncrement(); if (index &lt; 0) { nextIndex.decrementAndGet(); throw new IllegalStateException(&quot;too many thread-local indexed variables&quot;); } return index; } /** * @return {@code true} if and only if a new thread-local variable has been created */ public boolean setIndexedVariable(int index, Object value) { Object[] lookup = indexedVariables; if (index &lt; lookup.length) { Object oldValue = lookup[index]; lookup[index] = value; return oldValue == UNSET; } else { expandIndexedVariableTableAndSet(index, value); return true; } } InternalThreadLocalMap继承自UnpaddedInternalThreadLocalMap，为了好看一点我把父类中的相关代码放到了一起，dubbo借鉴netty代码也是这么干的。 FastThreadLocal最后看看FastThreadLocal是怎么把这几个核心类给串起来的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class FastThreadLocal&lt;V&gt; { private static final int variablesToRemoveIndex = InternalThreadLocalMap.nextVariableIndex(); private final int index; public FastThreadLocal() { index = InternalThreadLocalMap.nextVariableIndex(); } /** * Returns the current value for the current thread */ @SuppressWarnings(&quot;unchecked&quot;) public final V get() { InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get(); Object v = threadLocalMap.indexedVariable(index); if (v != InternalThreadLocalMap.UNSET) { return (V) v; } return initialize(threadLocalMap); } private V initialize(InternalThreadLocalMap threadLocalMap) { V v = null; try { v = initialValue(); } catch (Exception e) { PlatformDependent.throwException(e); } threadLocalMap.setIndexedVariable(index, v); addToVariablesToRemove(threadLocalMap, this); return v; } /** * Returns the initial value for this thread-local variable. * 这个方法一般会把覆盖 */ protected V initialValue() throws Exception { return null; } 八卦https://github.com/apache/dubbo/pull/1745","link":"/archives/4b47846d.html"},{"title":"PriorityQueue解析","text":"本文转载至github：https://github.com/CarpenterLee/JCFInternals/blob/master/markdown/8-PriorityQueue.md PriorityQueue总体介绍前面以Java ArrayDeque为例讲解了Stack和Queue，其实还有一种特殊的队列叫做PriorityQueue，即优先队列。优先队列的作用是能保证每次取出的元素都是队列中权值最小的（Java的优先队列每次取最小元素，C++的优先队列每次取最大元素）。这里牵涉到了大小关系，元素大小的评判可以通过元素本身的自然顺序（natural ordering），也可以通过构造时传入的比较器（Comparator，类似于C++的仿函数）。 Java中PriorityQueue实现了Queue接口，不允许放入null元素；其通过堆实现，具体说是通过完全二叉树（complete binary tree）实现的小顶堆（任意一个非叶子节点的权值，都不大于其左右子节点的权值），也就意味着可以通过数组来作为PriorityQueue的底层实现。 上图中我们给每个元素按照层序遍历的方式进行了编号，如果你足够细心，会发现父节点和子节点的编号是有联系的，更确切的说父子节点的编号之间有如下关系： leftNo = parentNo*2+1 rightNo = parentNo*2+2 parentNo = (nodeNo-1)/2 通过上述三个公式，可以轻易计算出某个节点的父节点以及子节点的下标。这也就是为什么可以直接用数组来存储堆的原因。 PriorityQueue的peek()和element操作是常数时间，add(), offer(), 无参数的remove()以及poll()方法的时间复杂度都是*log(N)*。 方法剖析add()和offer()add(E e)和offer(E e)的语义相同，都是向优先队列中插入元素，只是Queue接口规定二者对插入失败时的处理不同，前者在插入失败时抛出异常，后则则会返回false。对于PriorityQueue这两个方法其实没什么差别。 新加入的元素可能会破坏小顶堆的性质，因此需要进行必要的调整。 123456789101112131415//offer(E e)public boolean offer(E e) { if (e == null)//不允许放入null元素 throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1);//自动扩容 size = i + 1; if (i == 0)//队列原来为空，这是插入的第一个元素 queue[0] = e; else siftUp(i, e);//调整 return true;} 上述代码中，扩容函数grow()类似于ArrayList里的grow()函数，就是再申请一个更大的数组，并将原数组的元素复制过去，这里不再赘述。需要注意的是siftUp(int k, E x)方法，该方法用于插入元素x并维持堆的特性。 123456789101112//siftUp()private void siftUp(int k, E x) { while (k &gt; 0) { int parent = (k - 1) &gt;&gt;&gt; 1;//parentNo = (nodeNo-1)/2 Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0)//调用比较器的比较方法 break; queue[k] = e; k = parent; } queue[k] = x;} 新加入的元素x可能会破坏小顶堆的性质，因此需要进行调整。调整的过程为：从k指定的位置开始，将x逐层与当前点的parent进行比较并交换，直到满足x &gt;= queue[parent]为止。注意这里的比较可以是元素的自然顺序，也可以是依靠比较器的顺序。 element()和peek()element()和peek()的语义完全相同，都是获取但不删除队首元素，也就是队列中权值最小的那个元素，二者唯一的区别是当方法失败时前者抛出异常，后者返回null。根据小顶堆的性质，堆顶那个元素就是全局最小的那个；由于堆用数组表示，根据下标关系，0下标处的那个元素既是堆顶元素。所以直接返回数组0下标处的那个元素即可。 代码也就非常简洁： 123456//peek()public E peek() { if (size == 0) return null; return (E) queue[0];//0下标处的那个元素就是最小的那个} remove()和poll()remove()和poll()方法的语义也完全相同，都是获取并删除队首元素，区别是当方法失败时前者抛出异常，后者返回null。由于删除操作会改变队列的结构，为维护小顶堆的性质，需要进行必要的调整。 代码如下： 123456789101112public E poll() { if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0];//0下标处的那个元素就是最小的那个 E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x);//调整 return result;} 上述代码首先记录0下标处的元素，并用最后一个元素替换0下标位置的元素，之后调用siftDown()方法对堆进行调整，最后返回原来0下标处的那个元素（也就是最小的那个元素）。重点是siftDown(int k, E x)方法，该方法的作用是从k指定的位置开始，将x逐层向下与当前点的左右孩子中较小的那个交换，直到x小于或等于左右孩子中的任何一个为止。 123456789101112131415161718//siftDown()private void siftDown(int k, E x) { int half = size &gt;&gt;&gt; 1; while (k &lt; half) { //首先找到左右孩子中较小的那个，记录到c里，并用child记录其下标 int child = (k &lt;&lt; 1) + 1;//leftNo = parentNo*2+1 Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c;//然后用c取代原来的值 k = child; } queue[k] = x;} remove(Object o)remove(Object o)方法用于删除队列中跟o相等的某一个元素（如果有多个相等，只删除一个），该方法不是Queue接口内的方法，而是Collection接口的方法。由于删除操作会改变队列结构，所以要进行调整；又由于删除元素的位置可能是任意的，所以调整过程比其它函数稍加繁琐。具体来说，remove(Object o)可以分为2种情况：1. 删除的是最后一个元素。直接删除即可，不需要调整。2. 删除的不是最后一个元素，从删除点开始以最后一个元素为参照调用一次siftDown()即可。此处不再赘述。 具体代码如下： 1234567891011121314151617//remove(Object o)public boolean remove(Object o) { //通过遍历数组的方式找到第一个满足o.equals(queue[i])元素的下标 int i = indexOf(o); if (i == -1) return false; int s = --size; if (s == i) //情况1 queue[i] = null; else { E moved = (E) queue[s]; queue[s] = null; siftDown(i, moved);//情况2 ...... } return true;}","link":"/archives/f50feeee.html"},{"title":"RocketMQ RMQ_SYS_TRANS_HALF_TOPIC 爆掉的问题","text":"现象SaaS项目东郭反应，项目中发的事务消息一直在RMQ_SYS_TRANS_HALF_TOPIC中，并且不断增长。随即我们查看RocketMQ日志发现如下情况： 这个本来是RocketMQ正常的逻辑，发送事务消息后没有提交状态的话，当达到超时时间后，RocketMQ会回查本地事务状态。这里显示的是回查的次数超限，消息被移到了TRANS_CHECK_MAXTIME_TOPIC中。 不正常的是REAL_TOPIC变成了RMQ_SYS_TRANS_HALF_TOPIC，正常应该是原始的业务消息TOPIC才对。于是我们带着这个问题开始排查起来。 追踪一、排查一开始我们以为是Producer的问题，因为得到的反馈是这个消息没有被“消费”，所以我们开始排查Producer所在的项目。发现并没有什么问题。后来我们观察到上述日志中有一个DELAY=3，结合在网上查询的资料，认为可能是触发了RocketMQ的一个问题，就是事务消息进行了延迟发送。我们以为快接近真相了，我们开始查找Producer是否在发送事务消息时设置了DELAY参数。很快我们就失望了，Producer没有任何地方设置了DELAY参数。 二、翻阅源码我们回头去看上面那个日志，发现RECONSUME_TIME=1并且RETRY_TOPIC也不为空，这说明这个消息肯定是被消费者消费到了，但是由于某种原因消费失败了，触发了重试。于是我们开始看RocketMQ重试相关源码。我们首先找到了DELAY=3这个参数的来源： 123456789101112131415161718//在我们的消费者中设置了ConsumeConcurrentlyContext 延时级别context.setDelayLevelWhenNextConsume(getDelayLevelWhenNextConsume(reconsumeTimes));//可以看到这个delayLevel最终是会被发送到broker//org.apache.rocketmq.client.impl.consumer.ConsumeMessageConcurrentlyService#sendMessageBackpublic boolean sendMessageBack(final MessageExt msg, final ConsumeConcurrentlyContext context) { int delayLevel = context.getDelayLevelWhenNextConsume(); // Wrap topic with namespace before sending back message. msg.setTopic(this.defaultMQPushConsumer.withNamespace(msg.getTopic())); try { this.defaultMQPushConsumerImpl.sendMessageBack(msg, delayLevel, context.getMessageQueue().getBrokerName()); return true; } catch (Exception e) { log.error(&quot;sendMessageBack exception, group: &quot; + this.consumerGroup + &quot; msg: &quot; + msg.toString(), e); } return false;} 我们找到对应broker版本(4.6.0)的源码一步步找到了这里： 12345678910111213141516171819202122//org.apache.rocketmq.store.CommitLog#putMessagefinal int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag());if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) { // Delay Delivery if (msg.getDelayTimeLevel() &gt; 0) { if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) { msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()); } topic = ScheduleMessageService.SCHEDULE_TOPIC; queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // Backup real topic, queueId MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); msg.setTopic(topic); msg.setQueueId(queueId); }} 对照之前日志里的参数，sysFlag=8,delay=3，我们认为很可能走了这段逻辑，然后触发了事务消息进行了延迟发送的问题。继续看了延时消息发送的逻辑，没有找到问题，而且这也解释不了为什么REAL_TOPIC变成了``RMQ_SYS_TRANS_HALF_TOPIC` 三、真相上面还提到了一个RETRY_TOPIC，这个在之前的排查过程中没有发现有什么地方设置，于是我们搜索了一把，发现在这里： 123456789101112131415161718192021222324252627282930//org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl#sendMessageBackpublic void sendMessageBack(MessageExt msg, int delayLevel, final String brokerName) throws RemotingException, MQBrokerException, InterruptedException, MQClientException { try { String brokerAddr = (null != brokerName) ? this.mQClientFactory.findBrokerAddressInPublish(brokerName) : RemotingHelper.parseSocketAddressAddr(msg.getStoreHost()); this.mQClientFactory.getMQClientAPIImpl().consumerSendMessageBack(brokerAddr, msg, this.defaultMQPushConsumer.getConsumerGroup(), delayLevel, 5000, getMaxReconsumeTimes()); } catch (Exception e) { log.error(&quot;sendMessageBack Exception, &quot; + this.defaultMQPushConsumer.getConsumerGroup(), e); Message newMsg = new Message(MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()), msg.getBody()); String originMsgId = MessageAccessor.getOriginMessageId(msg); MessageAccessor.setOriginMessageId(newMsg, UtilAll.isBlank(originMsgId) ? msg.getMsgId() : originMsgId); newMsg.setFlag(msg.getFlag()); MessageAccessor.setProperties(newMsg, msg.getProperties()); //这里设置了RETRY_TOPIC MessageAccessor.putProperty(newMsg, MessageConst.PROPERTY_RETRY_TOPIC, msg.getTopic()); MessageAccessor.setReconsumeTime(newMsg, String.valueOf(msg.getReconsumeTimes() + 1)); MessageAccessor.setMaxReconsumeTimes(newMsg, String.valueOf(getMaxReconsumeTimes())); newMsg.setDelayTimeLevel(3 + msg.getReconsumeTimes()); this.mQClientFactory.getDefaultMQProducer().send(newMsg); } finally { msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQPushConsumer.getNamespace())); }} 很明显是个异常流程，那么到底是什么导致了这个异常流程呢？既然知道是在消费的时候出了异常，于是我们找到对应的消费者日志，发现如下错误： 这里Broker返回的错误是MESSAGE_ILIEGAL，在回过头去看重试相关代码，有了之前的经验这次很快就定位到了可能报这个错误的地方： 12345678910111213//第一处：org.apache.rocketmq.store.DefaultMessageStore#putMessage if (msg.getTopic().length() &gt; Byte.MAX_VALUE) { log.warn(&quot;putMessage message topic length too long &quot; + msg.getTopic().length()); return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null); }//第二处：org.apache.rocketmq.store.CommitLog.DefaultAppendMessageCallback#doAppend(long, java.nio.ByteBuffer, int, org.apache.rocketmq.store.MessageExtBrokerInner)if (propertiesLength &gt; Short.MAX_VALUE) { log.warn(&quot;putMessage message properties length too long. length={}&quot;, propertiesData.length); return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);} case PROPERTIES_SIZE_EXCEEDED: beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, result); 果断找运维要了store.log，发现如下错误： 1WARN SendMessageThread_1 - putMessage message topic length too long 149 所以应该就是第一处的问题了。至此问题的原因基本找到了，但还有以下问题： 为什么TOPIC会超长？ 重试的消息TOPIC规则为%RETRY%+consumerGroup： 1MixAll.getRetryTopic(this.defaultMQPushConsumer.getConsumerGroup()) 而我们的consumerGroup的规则为： 123public String getGroup() { return group + &quot;_&quot; + getTopic() + &quot;_&quot; + getTags();} 有问题的consumer的tags为：SAAS_PURCHASE_PURCHASE_ORDER_UPDATE||SAAS_PURCHASE_PURCHASE_ORDER_OPEN_RECEVIED||SAAS_PURCHASE_PURCHASE_ORDER_COMPLETED_RECEVIED 所以最终拼出来的TOPIC超出了长度。 为什么走了Catch里面的流程就会导致HALF队列爆掉？ 这是由于我们使用的RocketMQ-client版本为4.5.0，这个版本Catch里的代码有个bug，没有清除掉原始消息的事务消息标志TRANS_MSG=true。所以这个消息发出去后在broker端又会走事务消息的流程，并且还是带延时的。这会导致真实的TOPIC丢掉。 下面用一张图来说明一下： 事务消息消费失败，topic转为%RETRY%xxxx发送到broker，由于事务消息标志没有被清除，于是topic转成了RMQ_SYS_TRANS_HALF_TOPIC。又由于delay参数没有被清除，topic最后被转为了schedule_topic_xxxx。等到schedule执行时，消息会发到RMQ_SYS_TRANS_HALF_TOPIC中。由于不是Producer发的事务消息，所以拿不到LocalTransactionState。只能等待事务消息回查。 这时刚好又碰到我们的LocalTransactionListener的一个问题： 1234567891011121314151617181920212223public LocalTransactionState checkLocalTransaction(MessageExt messageExt) { Object msg = HessianUtils.decode(messageExt.getBody()); String topic = messageExt.getTopic(); String tag = messageExt.getTags(); //由于拿着rmq_sys_trans_half_topic来获取handler所以肯定获取不到。 LocalTransactionHandler localTransacationHandler = getLocalTransacationHandler(topic, tag); String msgId = messageExt.getMsgId(); if( localTransacationHandler == null ){ logger.error(&quot;localTransacationHandler is empty should never happened! msgId={}, arg={}&quot;, msgId, JSON.toJSONString(msg)); //于是这个地方会返回COMMIT_MESSAGE return LocalTransactionState.COMMIT_MESSAGE; } boolean checkResult = false; try { checkResult = localTransacationHandler.localTransactionCheck(msgId, msg); } catch (Exception e) { logger.error(&quot;localTransacationCheck failed! msgId={}, arg={}&quot;, msgId, JSON.toJSONString(msg), e); checkResult = false; } return checkResult ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE;} Broker收到COMMIT_MESSAGE后会将消息写往REAL_TOPIC中。而此时REAL_TOPIC早已变成了RMQ_SYS_TRANS_HALF_TOPIC。就这样，RMQ_SYS_TRANS_HALF_TOPIC 爆掉了。 解决 首先我们将handler为空时返回COMMIT_MESSAGE，改为了ROLLBACK_MESSAGE。 升级stone中RocketMQ为4.6.1，可以看到在Catch代码中多了一行： 1MessageAccessor.clearProperty(newMsg, &quot;TRAN_MSG&quot;); 有问题的consumer将tag拆分 第一步和第二步只能解决RMQ_SYS_TRANS_HALF_TOPIC爆掉的问题。但是topic超长还是会有问题。所以目前暂时是将consumer的tag拆开。","link":"/archives/cfa05355.html"},{"title":"Spring JPA 自定义关联分页查询（动态条件）","text":"适用于多张表关联，条件是动态的情况下使用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263StringBuilder nativeSql = new StringBuilder(&quot;select o.* from t_order o,t_order_detail od,t_order_goods og where o.id = od.order_id and o.id = og.order_id and o.company_id=:companyId&quot;); StringBuilder countSql = new StringBuilder(&quot;select count(*) from t_order o,t_order_detail od,t_order_goods og where o.id = od.order_id and o.id = og.order_id and o.company_id=:companyId&quot;); if (StringUtils.isNotBlank(orderQueryVM.getGoodsName())) { nativeSql.append(&quot; and &quot;).append(&quot;og.goods_name like :goodsName&quot;); countSql.append(&quot; and &quot;).append(&quot;og.goods_name like :goodsName&quot;); } if (StringUtils.isNotBlank(orderQueryVM.getCustomerName())) { nativeSql.append(&quot; and &quot;).append(&quot;od.customer_name like :customerName&quot;); countSql.append(&quot; and &quot;).append(&quot;od.customer_name like :customerName&quot;); } if (orderQueryVM.getOrderStatus() != null) { nativeSql.append(&quot; and &quot;).append(&quot;o.order_status=:orderStatus&quot;); countSql.append(&quot; and &quot;).append(&quot;o.order_status=:orderStatus&quot;); } if (orderQueryVM.getSettleStatus() != null) { nativeSql.append(&quot; and &quot;).append(&quot;o.settle_status=:settleStatus&quot;); countSql.append(&quot; and &quot;).append(&quot;o.settle_status=:settleStatus&quot;); } if (orderQueryVM.getStartDate() != null &amp;&amp; orderQueryVM.getEndDate() != null) { nativeSql.append(&quot; and &quot;).append(&quot;o.order_date&lt;=:endDate&quot;); countSql.append(&quot; and &quot;).append(&quot;o.order_date&lt;=:endDate&quot;); nativeSql.append(&quot; and &quot;).append(&quot;o.order_date&gt;=:startDate&quot;); countSql.append(&quot; and &quot;).append(&quot;o.order_date&gt;=:startDate&quot;); } nativeSql.append(&quot; order by created_date desc &quot;); Pageable pageable = new PageRequest(page,pagesize,new Sort(Direction.DESC,&quot;created_date&quot;)) Query nativeQuery = em.createNativeQuery(nativeSql.toString(), Order.class); //设置分页 nativeQuery.setFirstResult(pageable.getOffset()); nativeQuery.setMaxResults(pageable.getPageSize()); nativeQuery.setParameter(&quot;companyId&quot;, orderQueryVM.getCompanyId()); Query countQuery = em.createNativeQuery(countSql.toString()); countQuery.setParameter(&quot;companyId&quot;, orderQueryVM.getCompanyId()); if (StringUtils.isNotBlank(orderQueryVM.getGoodsName())) { nativeQuery.setParameter(&quot;goodsName&quot;, &quot;%&quot; + orderQueryVM.getGoodsName() + &quot;%&quot;); countQuery.setParameter(&quot;goodsName&quot;, &quot;%&quot; + orderQueryVM.getGoodsName() + &quot;%&quot;); } if (StringUtils.isNotBlank(orderQueryVM.getCustomerName())) { nativeQuery.setParameter(&quot;customerName&quot;, &quot;%&quot; + orderQueryVM.getCustomerName() + &quot;%&quot;); countQuery.setParameter(&quot;customerName&quot;, &quot;%&quot; + orderQueryVM.getCustomerName() + &quot;%&quot;); } if (orderQueryVM.getOrderStatus() != null) { nativeQuery.setParameter(&quot;orderStatus&quot;, orderQueryVM.getOrderStatus().name()); countQuery.setParameter(&quot;orderStatus&quot;, orderQueryVM.getOrderStatus().name()); } if (orderQueryVM.getSettleStatus() != null) { nativeQuery.setParameter(&quot;settleStatus&quot;, orderQueryVM.getSettleStatus().name()); countQuery.setParameter(&quot;settleStatus&quot;, orderQueryVM.getSettleStatus().name()); } if (orderQueryVM.getStartDate() != null &amp;&amp; orderQueryVM.getEndDate() != null) { nativeQuery.setParameter(&quot;endDate&quot;, orderQueryVM.getEndDate()); countQuery.setParameter(&quot;endDate&quot;, orderQueryVM.getEndDate()); nativeQuery.setParameter(&quot;startDate&quot;, orderQueryVM.getStartDate()); countQuery.setParameter(&quot;startDate&quot;, orderQueryVM.getStartDate()); } List&lt;Order&gt; orderList = nativeQuery.getResultList(); //获取总数 BigInteger count = (BigInteger) countQuery.getSingleResult(); Page&lt;Order&gt; page = new PageImpl(orderList, pageable, count.intValue()); return page;","link":"/archives/4072076b.html"},{"title":"Stream的TerminalOp执行原理","text":"Stream在执行intermediate(例如 map、filter)操作时，会形成referencePipeline 双向链表。 TermianlOp执行时遍历链表： 123for ( AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) { sink = p.opWrapSink(p.previousStage.combinedFlags, sink);} 执行StatelessOp 中Sink的OnWrapSink。(通过Sink 中ChainedReference 翻转) 所以Stream中的元素是依次应用intermediate操作。并不是所有元素应用完第一个intermediate操作，在应用下一个。 PS:使用Stream时，首先会构建一个HEAD-源阶段（Stream()），然后经历StatelessOp-中间阶段（map、filter），最终通过TermianlOp（reduce等）","link":"/archives/2c656d9.html"},{"title":"new Thread() 对象什么时候被回收","text":"在Java中什么样的对象会被回收呢？ 通过引用计数判断不存在引用的对象。 通过遍历GC Root来判断不存在引用的对象。 假设有如下一段代码（推荐使用线程池）：1234567891011public void test(){ Thread thread = new Thread(new Runnable() { @Override public void run() { while(true){ //do something } } }); thread.start();} 我们都知道，当test()方法退出时，调用栈中栈帧内局部变量表保存的局部变量(thread)都会被销毁。也就是说new Thread()的引用不存在了，但是执行GC后（测试可使用System.gc())，我们发现线程还是在运行的。来看看线程的生命周期图（图片来源互联网）:从上图我们可以看到，只有当run方法结束时，线程才会dead。 猜测：在run方法中，其实会持有线程对象的this引用，也就是说，这个线程对象其实是存在GC Root 引用的，所以没有被GC。","link":"/archives/e6a5a040.html"},{"title":"tk.mybatis与Activiti共存问题解决","text":"由于tk.mybatis依赖了persistence-api，会让Activiti装配JpaProcessEngineAutoConfiguration，因为其@conditonalOnclass(name = “javax.persistence.EntityManagerFactory”)。 但实际没有使用JPA，导致启动报错。如果排除persistence-api，又会导致tk.mybatis报错。 参考了一番其它的人做法，无论是各种排除还是添加依赖都无效。 最终自己的解决方案是： 首先排除activiti jpa的自动装配： 1@SpringBootApplication(exclude={JpaProcessEngineAutoConfiguration.class})。 然后找到activiti中的DataSourceProcessEngineAutoConfiguration.class 复制出源码，在自己的项目中添加一个同名文件（不同名也行）。然后粘贴内容到新建的文件中。最后删掉： 1@ConditionalOnMissionClass(name = &quot;javax.persistence.EntityManagerFactory&quot;) Ok,搞定！","link":"/archives/7008e148.html"},{"title":"为什么阿里禁止通过Executors创建线程池","text":"Executors是通过new一个ThreadPoolExecutor来创建的线程池。来看看ThreadPoolExecutor的构造方法： 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } 方法上的Javadoc： 1234567891011* @param corePoolSize the number of threads to keep in the pool, even* if they are idle, unless {@code allowCoreThreadTimeOut} is set* @param maximumPoolSize the maximum number of threads to allow in the* pool* @param keepAliveTime when the number of threads is greater than* the core, this is the maximum time that excess idle threads* will wait for new tasks before terminating.* @param unit the time unit for the {@code keepAliveTime} argument* @param workQueue the queue to use for holding tasks before they are* executed. This queue will hold only the {@code Runnable}* tasks submitted by the {@code execute} method. 解释一下：corePoolSize ：保持在线程池中的线程，哪怕这几个线程是空闲的。除非设置了allowCoreThreadTimeOut。maximumPoolSize：线程池中允许的最大的线程数量。keepAliveTime：多余corePoolSize 设置的线程的存活时间（比如corePoolSize 3，maximumPoolSize 10，那么剩下的7个线程将只能存活keepAliveTime）。unit ：keepAliveTime的时间单位workQueue：保存corePoolSize 线程处理不了的任务（比如corePoolSize 3，但是有10个任务要处理，那么剩下的7个任务将存储在workQueue中）。当此队列满了之后，会再次创建不超过maximumPoolSize大小的线程来处理。 好，看完了ThreadPoolExecutor构造函数，再来看看Executors是怎么设置这些参数创建线程池的，以及会带来哪些问题。 看看Executors创建线程池的源码： newFixedThreadPool12345 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} corePoolSize、maximumPoolSize 设置为相同(nThreads)大小，也就是说这个线程池内部会一直存在nThreads数量的线程。并且由于corePoolSize和maximumPoolSize 相同，keepAliveTime也就无意义了，所以设置为0L。这个线程池使用的是LinkedBlockingQueue（无界队列）来存corePoolSize线程无法处理的任务。那么这个线程池问题在哪里呢？最大的问题在于workQueue使用了无界队列，当任务数多到线程池处理不过来时，任务全部进入workQueue，会消耗很大的内存，甚至OOM。 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} 可以发现newSingleThreadExecutor 是 newFixedThreadPool的一个具化版本。指定了固定的nThreads：1。所以这个线程池的问题跟newFixedThreadPool一样。当任务过多时，可能出现OOM。 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } corePoolSize 设置为0，也就是说默认这个线程池中不会有线程创建。 使用的workQueue是SynchronousQueue，只有被消费才能继续生产。此时来了一个任务，发现没有线程来消费，于是创建一个线程来消费。并且这个线程在完成任务后最多存活60秒。如果此时来了很多任务。那么这个线程最大可创建Integer.MAX_VALUE个线程。这就是这个线程池的问题所在了，线程数量可以基本上说是无限制，可能导致资源耗尽。 Executors中还有很多创建线程池的工厂方法，或多或少都存在上述问题。通过上面的问题可以发现，要创建一个可靠的线程池，最好还是手动创建，并且合理指定corePoolSize、maximumPoolSize 、workQueue等参数。 例如：为了避免OOM，我们可以使用有界队列ArrayBlockingQueue来替代无界队列。为了避免线程过多资源耗尽，我们需要结合实际情况来指定一个maximumPoolSize，而不是粗暴的设置为Integer.MAX_VALUE。 12345678new ThreadPoolExecutor( 2, 8, 30L, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(1000), Executors.defaultThreadFactory(), new AbortPolicy()); 上面这个线程池，当添加进任务时，默认创建2个线程来处理任务。如果又来了一个任务，此时会进入ArrayBlockingQueue（workQueue）排队，当workQueue满了（1000个任务）会在创建6个线程来处理任务。如果此时还有任务添加进来，则会执行AbortPolicy策略，默认是拒绝添加。当所有任务处理完成后，这6个线程在空闲30秒后将会被销毁。 实际使用时应该结合实际情况调整，并且自定义ThreadFactory以达到设置线程名称的目的。 原创，如有雷同纯属巧合。","link":"/archives/3223999.html"},{"title":"从字节码来说明i++与++i到底有什么不同","text":"看字节码之前需要先了解相关概念，如栈帧、操作数栈、局部变量表。栈帧是JVM中很重要的一个概念，因为JVM是基于栈的架构。一个方法的调用其实就是栈帧入栈出栈的过程。栈顶栈帧就是当前方法调用。一个栈帧中包含： 局部变量表 操作数栈 动态链接 方法返回地址 这里i++、 ++i涉及到的就是局部变量表和操作数栈。具体信息可参考：《Java虚拟机规范》 局部变量表存储的是方法的参数以及内部定义的变量的值，操作数栈也是一个栈结构，用来执行方法中的指令。 好了，来看一个代码片段： 12345678class Scratch { public static void main(String[] args) { int i=0,j=0,m=0; j = i++; m = ++i; }} 为了不产生其他多过信息，这里只写了关键代码。首先可以通过javac 将源码编译成class： 1javac scratch.java 执行完成后将看到Scratch.class 文件，通过javap命令查看字节码： 1javap -c Scratch &gt; scratch.txt 为了方便查看将结果输出到了scratch.txt，打开此文件将看到如下信息： 12345678910111213141516171819202122232425Compiled from &quot;scratch.java&quot;class Scratch { Scratch(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_0 1: istore_1 2: iconst_0 3: istore_2 4: iconst_0 5: istore_3 6: iload_1 7: iinc 1, 1 10: istore_2 11: iinc 1, 1 14: iload_1 15: istore_3 16: return} 关注main方法 0-5，可以发现对应的是： 1int i=0,j=0,m=0; 主要是声明变量并初始化为0。我们可以发现下划线后面跟了一个数字，这里应该代表的是变量在局部变量表中的位置。i：1j：2m：3 再关注main方法：6、7、10：iload_1 表示将局部变量表中位置1的数据放入操作数栈中(这里对应的是i，此时i的值为0)然后pop出来赋值给j。然后再将i自增iinc。最后istore_2存储j到局部变量表中。操作完成后i=1，j=1。最后关注main方法：11、14、15：iinc首先自增i，然后iload_1将局部变量表中位置1的数据放入操作数栈中(这里对应的是i，此时i的值为2)然后pop出来赋值给m。最后istore_3存储m到局部变量表中。操作完成后i=2，j=1，m=2。 这就是为什么大家都说，i++是先赋值后自增，而++i是先自增后赋值的原因。 这里要说明的是，如果是单独的i++、++i是没有什么区别的。","link":"/archives/ade4c276.html"},{"title":"使用Mybatis批量更新的一个小问题","text":"批量更新的方式有很多种，例如update case when，foreach update等，今天在使用其中一种foreach update时一直报SQL语法错误，看了半天没看出哪里有问题: 1234567891011121314&lt;update id=&quot;updateBatch&quot; parameterType=&quot;list&quot;&gt; &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;;&quot; index=&quot;index&quot;&gt; update test &lt;set&gt; status = #{item.status,jdbcType=BIGINT}, amount = #{item.amount,jdbcType=BIGINT}, version = version+1, gmt_modified = now(), &lt;/set&gt; &lt;where&gt; id = #{item.id} &lt;/where&gt; &lt;/foreach&gt; &lt;/update&gt; 非常简单的update SQL，通过Mybatis foreach 生成多个update SQL同时执行，但是运行时一直报： 123456### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'update test SET amount = -116534270, version' at line 10; bad SQL grammar []; nested exception is com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'update test SET amount = -116534270, version' at line 10 看到这个错误下意识的认为肯定是sql哪里写的不对有语法错误，可是检查了半天没发现问题，而且将报错的sql 通过navicat运行也可以通过。 后来查到如果批量执行语句需要将database connection url中加上如下参数： 1allowMultiQueries=true 完整的url例如： 1jdbc:mysql://x.x.x.x:3306/xxxx?allowMultiQueries=true&amp;amp;autoReconnect=true&amp;amp;useUnicode=true&amp;amp;characterset=utf8mb4 不得不说MySQL报错信息实在是太模糊了。😓","link":"/archives/e8013d2a.html"},{"title":"UUID优化方案","text":"数据ID生成方案中UUID相对来说是最简单的，但是其也有不少缺点： 1.没有排序，无法保证趋势递增。2.UUID往往是使用字符串存储，查询的效率比较低。3.存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。4.传输数据量大5.不可读。 常见优化方案：1.优化字符串为BigInteger 12345678private static BigInteger pair() { UUID myuuid = UUID.randomUUID(); //UUID长度为128位 ByteBuffer bb = ByteBuffer.wrap(new byte[16]); bb.putLong(myuuid .getMostSignificantBits()); bb.putLong(myuuid .getLeastSignificantBits()); return new BigInteger(bb.array());} 2.去掉符号： 12345678private static BigInteger pair(UUID uuid) { BigInteger value1 = BigInteger.valueOf(uuid.getMostSignificantBits()); BigInteger value2 = BigInteger.valueOf(uuid.getLeastSignificantBits()); if (value1.compareTo(value2) &lt; 0) { return value2.multiply(value2).add(value1); } return value1.multiply(value1).add(value1).add(value2);}","link":"/archives/421cfd7c.html"},{"title":"利用mybatis标签替换硬编码","text":"建议利用mybatis标签替换硬编码 背景在项目中偶尔看到这样的代码： 123456789&lt;sql id=&quot;querySqlString&quot;&gt; &lt;where&gt; 1=1 &lt;if test=&quot;fundsOrderIdList != null and fundsOrderIdList.size()&gt;0&quot;&gt; and funds_order_id IN &lt;foreach collection=&quot;fundsOrderIdList&quot; item=&quot;id&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #{id} &lt;/foreach&gt; &lt;/if&gt; 这段代码中有个1=1很扎眼，这个不是bug，也没有什么性能问题，只是程序员世代传承下来的一个习惯。 故事在很久以前，充满智慧的程序员为了解决动态条件拼接的问题，发明了1=1这个写法，对应的还有1=0的写法，我们来看看这个写法在以前是怎么解决问题的： 1234567sql = &quot;select * from car_table where 1=1&quot;for(Condtion condition:conditions){ /**假如没有1=1，第一个条件直接拼接上and语法就错误了 *还得做出额外判断才行 */ sql = sql + &quot; and &quot; + condition.field + &quot; = &quot; + condition.value} 确实很巧妙，而且也没有性能问题，不信我给你举个🌰: 1select * from pay_channel_with_bank where 1=1 and channel_code = '50008'; 这是一条很简单的SQL，其中就有1=1的写法，我们来看看MySQL查询优化器优化后实际执行的SQL: 12345EXPLAINselect * from pay_channel_with_bank where 1=1 and channel_code = '50008';SHOW WARNINGS;实际执行的SQL:/* select#1 */ select 此处省略很多column from `online_paychannel`.`pay_channel_with_bank` where (`online_paychannel`.`pay_channel_with_bank`.`channel_code` = 50008) 可以看到1=1已经被优化掉了。 结论虽然这种写法没啥大问题，但是代码是给人看的。如果不了解这种写法，乍一眼看过去肯定有点懵。 而且我们现在使用的Mybatis提供的&lt;where&gt;标签本身就会帮我们做优化: 123456789101112131415161718private void applyPrefix(StringBuilder sql, String trimmedUppercaseSql) { if (!prefixApplied) { prefixApplied = true; if (prefixesToOverride != null) { for (String toRemove : prefixesToOverride) { //此处会移除一些前缀 if (trimmedUppercaseSql.startsWith(toRemove)) { sql.delete(0, toRemove.trim().length()); break; } } } if (prefix != null) { sql.insert(0, &quot; &quot;); sql.insert(0, prefix); } } } WhereSqlNode中定义的prefixesToOverride: 1private static List&lt;String&gt; prefixList = Arrays.asList(&quot;AND &quot;,&quot;OR &quot;,&quot;AND\\n&quot;, &quot;OR\\n&quot;, &quot;AND\\r&quot;, &quot;OR\\r&quot;, &quot;AND\\t&quot;, &quot;OR\\t&quot;); 所以使用了&lt;where&gt;标签后可以放心大胆的去掉1=1。","link":"/archives/ad1a887a.html"},{"title":"MySQL可重复读和幻读","text":"可重复读描述的是一个事务在处理数据时，多次查询此数据得到的结果是一样的。MySQL的InnoDB存储引擎通过多版本并发控制（Multi_Version Concurrency Control, MVCC）机制来解决该问题。幻读描述的是MVCC不能阻止插入新的数据，导致多次查询时数据记录不一致。","link":"/archives/16902655.html"},{"title":"各种加密方式的问题","text":"对称加密最大的问题就是密钥的传输问题。于是乎出现了非对称加密。公钥完全公开，谁都可以使用。非对称加密最大的问题就是身份确认的问题。怎么能确认是不是正确的人使用公钥加密的信息呢。于是乎出现了数字签名，使用对方公钥的人，用自己的私钥签名，然后对方用签名的人的公钥解密。","link":"/archives/d7f22001.html"},{"title":"对变量加锁后是否还需要使用volatile","text":"大家都知道volatile保证了变量在线程间的可见性（主内存与CPU缓存（线程内存）间）。Lock与synchronized也可以保证可见性，还能保证原子性。那么使用了Lock与synchronized之后，变量是否就不用加volatile了？ 12345678910111213141516171819202122232425262728public class Test{ public boolean t=false;}main(){Test test = new Test();Thread a = new Thread(()-&gt;{ for(;;){ if(test.t){ sout(&quot;t is true&quot;) break; } }}).start();Thread b = new Thread(()-&gt;{ TimeUnit.MILLISECONDS.sleep(20) synchronized(test){ test.t=true; } }}).start();a.join();b.join();} 在上面伪代码中，a线程死循环判断test中的t为true时结束。b线程模拟执行20毫秒的业务后将test中t更改为true。正常情况下a线程应该会结束（synchronized保证了可见性和原子性），但事实并不是这样。 这是因为虽然b线程更改t的值并更新到了主内存，但是a线程cpu一直忙于for死循环，没有空去主内存获取最新的值。做个试验，将a线程改成如下： 123456789Thread a = new Thread(()-&gt;{ for(;;){ TimeUnit.MILLISECONDS.sleep(2) if(test.t){ sout(&quot;t is true&quot;) break; } }}).start(); 再次运行，发现程序正常了。原因在于线程sleep后，cpu空闲下来，有时间去更新t的值了。 另外一个方法（正确的做法）： volatile private boolean t=false; 变量前加上volatile，则当t的值发生变化时，强制更新缓存中的值。所以保险情况下，该加volatile还是得加。 原创，如有雷同纯属巧合。","link":"/archives/5cf0b88d.html"},{"title":"深入开源框架底层之ASM","text":"什么是 ASM ？ASM 是一个 Java 字节码操控框架。它能被用来动态生成类或者增强既有类的功能。ASM 可以直接产生二进制 class 文件，也可以在类被加载入 Java 虚拟机之前动态改变类行为。Java class 被存储在严格格式定义的 .class 文件里，这些类文件拥有足够的元数据来解析类中的所有元素：类名称、方法、属性以及 Java 字节码（指令）。ASM 从类文件中读入信息后，能够改变类行为，分析类信息，甚至能够根据用户要求生成新类。 为什么要动态生成 Java 类？想象一下，如果开源框架要求你添加各种Java类来实现诸如log、cache、transaction等功能，我想这个开源框架你肯定不会用吧。动态生成类可以减少对你代码的侵入，提高使用者的效率。 为什么选择ASM？最直接的改造 Java 类的方法莫过于直接改写 class 文件。Java 规范详细说明了 class 文件的格式，直接编辑字节码确实可以改变 Java 类的行为。直到今天，还有一些 Java 高手们使用最原始的工具，如 UltraEdit 这样的编辑器对 class 文件动手术。是的，这是最直接的方法，但是要求使用者对 Java class 文件的格式了熟于心：小心地推算出想改造的函数相对文件首部的偏移量，同时重新计算 class 文件的校验码以通过 Java 虚拟机的安全机制。 可以发现，直接操作class文件是比较麻烦的，就跟为什么我们都选择使用框架一样，框架屏蔽了底层的复杂性。ASM就是操作class的一把利器。 使用 ASM 编程ASM提供了两种API： CoreAPI（ClassVisitor 、MethodVisitor等） TreeAPI（ClassNode，MethodNode等） 区别是CoreAPI基于事件模型，定义了Class中各个元素的Visitor，不需要加载整个Class到内存中。而TreeAPI以Tree结构将Class整个结构读取到内存中。从使用角度来说TreeAPI更为简单。 以下示例采用的是CoreAPI方式。 添加Maven： 12345&lt;dependency&gt; &lt;groupId&gt;org.ow2.asm&lt;/groupId&gt; &lt;artifactId&gt;asm&lt;/artifactId&gt; &lt;version&gt;5.0.4&lt;/version&gt;&lt;/dependency&gt; 使用的相对比较稳定，使用比较多的版本5.0.4。 首先说明一下，修改Class有多种方式，例如直接修改当前Class，或者生成Class的子类，从而达到增强的效果。 下面的示例就是通过生成指定Class的子类，从而达到增强的效果，好处是对原有Class无侵入，并且可以实现多态的效果。 首先定义一个我们要增强的类： 12345678910111213141516package com.zjz;import java.util.Random;/** * @author zhaojz created at 2019-08-22 10:49 */public class Student { public String name; public void studying() throws InterruptedException { System.out.println(this.name+&quot;正在学习...&quot;); Thread.sleep(new Random().nextInt(5000)); }} 接下来首先定义一个ClassReader： 1ClassReader classReader = new ClassReader(&quot;com.zjz.Student&quot;); 然后再定义一个ClassWriter: 1ClassWriter classWriter = new ClassWriter(classReader, ClassWriter.COMPUTE_MAXS); ClassWriter.COMPUTE_MAXS 表示自动计算局部变量和操作数栈大小。更多其它选项可参考：asm.ow2.io 接下来开始正式访问Class： 12345678910111213141516171819202122232425262728293031323334353637//通过ClassVisitor访问Class（匿名类的方式，可以自行定义为一个独立的类）//ASM5为JVM字节码指令操作码ClassVisitor classVisitor = new ClassVisitor(Opcodes.ASM5, classWriter) { //声明一个全局变量，表示增强后生成的子类的父类 String enhancedSuperName; @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) { //拼接需要生成的子类的类名：Student$EnhancedByASM String enhancedName = name+&quot;$EnhancedByASM&quot;; //将Student设置为父类 enhancedSuperName = name; super.visit(version, access, enhancedName, signature, enhancedSuperName, interfaces); } @Override public FieldVisitor visitField(int access, String name, String desc, String signature, Object value) { //这里是演示字段访问 System.out.println(&quot;Field:&quot; + name); return super.visitField(access, name, desc, signature, value); } @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { System.out.println(&quot;Method:&quot; + name); MethodVisitor mv = super.visitMethod(access, name, desc, signature, exceptions); MethodVisitor wrappedMv = mv; //判断当前读取的方法 if (name.equals(&quot;studying&quot;)) { //如果是studying方法，则包装一个方法的Visitor wrappedMv = new StudentStudyingMethodVisitor(Opcodes.ASM5, mv); }else if(name.equals(&quot;&lt;init&gt;&quot;)){ //如果是构造方法，处理子类中父类的构造函数调用 wrappedMv = new StudentEnhancedConstructorMethodVisitor(Opcodes.ASM5, mv,enhancedSuperName); } return wrappedMv; }}; 接下来重点看看MethodVisitor： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//Studying方法的Visitorstatic class StudentStudyingMethodVisitor extends MethodVisitor{ public StudentStudyingMethodVisitor(int i, MethodVisitor methodVisitor) { super(i, methodVisitor); } //MethodVisitor 中定义了不同的visitXXX()方法，代表的不同的访问阶段。 //visitCode表示刚刚进入方法。 @Override public void visitCode() { //添加一行System.currentTimeMillis()调用 visitMethodInsn(Opcodes.INVOKESTATIC, &quot;java/lang/System&quot;, &quot;currentTimeMillis&quot;, &quot;()J&quot;, false); //并且将其存储在局部变量表内位置为1的地方 visitVarInsn(Opcodes.LSTORE, 1); //上面两个的作用就是在Studying方法的第一行添加 long start = System.currentTimeMillis() } //visitInsn 表示访问进入了方法内部 @Override public void visitInsn(int opcode) { //通过opcode可以得知当前访问到了哪一步，如果是&gt;=Opcodes.IRETURN &amp;&amp; opcode &lt;= Opcodes.RETURN 表明方法即将退出 if ((opcode &gt;= Opcodes.IRETURN &amp;&amp; opcode &lt;= Opcodes.RETURN)){ //加载局部变量表中位置为1的数据，也就是start的数据，并传入给下面的方法 visitVarInsn(Opcodes.LLOAD, 1); //然后调用自定义的一个工具方法，用来输出耗时 visitMethodInsn(Opcodes.INVOKESTATIC, &quot;com/zjz/Before&quot;, &quot;end&quot;, &quot;(J)V&quot;, false); } super.visitInsn(opcode); }}static class StudentEnhancedConstructorMethodVisitor extends MethodVisitor{ //定义一个全局变量记录父类名称 private String superClassName; public StudentEnhancedConstructorMethodVisitor(int i, MethodVisitor methodVisitor,String superClassName) { super(i, methodVisitor); this.superClassName = superClassName; } @Override public void visitMethodInsn(int opcode, String owner, String name, String desc, boolean b) { //当开始初始化构造函数时，先访问父类构造函数,类似源码中的super() if (opcode==Opcodes.INVOKESPECIAL &amp;&amp; name.equals(&quot;&lt;init&gt;&quot;)){ owner = superClassName; } super.visitMethodInsn(opcode, owner, name, desc, b); }} 此时ClassVisitor还没有数据的输入，只定义了数据的输出 new ClassVisitor(Opcodes.ASM5, classWriter)，所以还需要： 1classReader.accept(classVisitor, ClassReader.SKIP_DEBUG); 到此就完成了Class的读取，访问修改，输出的过程。 细心的观众就会发现了，输出到哪里了？怎么样访问新生成的类呢？所以我们需要定义一个ClassLoader来加载我们生成的Class： 12345static class StudentClassLoader extends ClassLoader{ public Class defineClassFromClassFile(String className,byte[] classFile) throws ClassFormatError{ return defineClass(className, classFile, 0, classFile.length); } } 然后通过ClassWriter获取新生成的类的字节数组，并加载到JVM中： 12byte[] data = classWriter.toByteArray();Class subStudent = classLoader.defineClassFromClassFile(&quot;com.zjz.Student$EnhancedByASM&quot;, data); 到此就完成了一个class的生成，上面的代码完成的是一个很简单的事情：记录学习时间。 总结一下： ASM CoreAPI 核心的三个东西就是ClassReader、Visitor、ClassWriter，通过责任链模式将其链接起来。 Visitor通过访问者模式进行方法、字段等等属性的访问，如果需要修改一个方法和字段，只需要将其原本的Visitor给Wrap一下即可。 关于如何进行代码的hook需要理解JVM相关字节码指令，以及ASM的相关OpCode。 ASM Bytecode Outline 2017但是那么多指令、OpCode、符号怎么记得住呢？比如上面代码中的： 12visitMethodInsn(Opcodes.INVOKESTATIC, &quot;java/lang/System&quot;, &quot;currentTimeMillis&quot;, &quot;()J&quot;, false);visitVarInsn(Opcodes.LSTORE, 1); Opcodes.INVOKESTATIC 、Opcodes.LSTORE、()J，是不是看着就晕？其实除了熟能生巧外，还可以使用工具。 如果你使用的是IDEA，那么可以安装上ASM Bytecode Outline 2017插件。然后在源文件上右键选择Show Bytecode Outline，你将会看到如下视图： 切换的ASMified视图，你会看到跟我们上面写的一样的代码，直接Copy过来使用即可。 查看示例完整源代码：asm_demo 参考资料： https://asm.ow2.io/ https://www.ibm.com/developerworks/cn/java/j-lo-asm30/index.html https://juejin.im/post/5b549bcbe51d45169c1c8b66","link":"/archives/58ee9111.html"},{"title":"获取jar中的文件注意事项","text":"获取resources下的文件Java有很多种方法。但是如果你的程序最终打成jar发布。那么需要注意你是否以流inputstream读取。因为jar中的文件路径为jar!xxxxxx 简单的使用path 或者getResouces肯定获取不到。","link":"/archives/7f9f876c.html"},{"title":"记一个Spring Data JPA自定义分页查询BUG","text":"官方给出的自定义分页查询的示例是这样的： 123456public interface UserRepository extends JpaRepository&lt;User, Long&gt; { @Query(value = &quot;SELECT * FROM USERS WHERE LASTNAME = ?1&quot;, countQuery = &quot;SELECT count(*) FROM USERS WHERE LASTNAME = ?1&quot;, nativeQuery = true) Page&lt;User&gt; findByLastname(String lastname, Pageable pageable);} https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#jpa.query-methods.at-query 然后实际执行时报错： 1org.springframework.data.jpa.repository.query.InvalidJpaQueryMethodException 这是因为在使用NativeQuery时，会有这样一个验证： 123456789public NativeJpaQuery(JpaQueryMethod method, EntityManager em, String queryString, EvaluationContextProvider evaluationContextProvider, SpelExpressionParser parser) { super(method, em, queryString, evaluationContextProvider, parser); JpaParameters parameters = method.getParameters(); boolean hasPagingOrSortingParameter = parameters.hasPageableParameter() || parameters.hasSortParameter(); boolean containsPageableOrSortInQueryExpression = queryString.contains(&quot;#pageable&quot;) || queryString.contains(&quot;#sort&quot;); if(hasPagingOrSortingParameter &amp;&amp; !containsPageableOrSortInQueryExpression) { throw new InvalidJpaQueryMethodException(&quot;Cannot use native queries with dynamic sorting and/or pagination in method &quot; + method); }} 当参数中包含Pageable或者Sort时，SQL语句中必须包含 12#pageable#sort 参考了众多解决方案都无效。例如 12?#{#pageable}\\n#pageable\\ https://stackoverflow.com/questions/38349930/spring-data-and-native-query-with-pagination 最终发现，其实只需要将#pageable合理的作为注释包含在SQL里即可。我使用的Mysql，最终解决方案为： 123456public interface UserRepository extends JpaRepository&lt;User, Long&gt; { @Query(value = &quot;SELECT * FROM USERS WHERE LASTNAME = ?1 /*#pageable*/&quot;, countQuery = &quot;SELECT count(*) FROM USERS WHERE LASTNAME = ?1&quot;, nativeQuery = true) Page&lt;User&gt; findByLastname(String lastname, Pageable pageable);} 我使用的是Spring boot 1.5.4，在新版本中应该此问题已经被修复了。","link":"/archives/de80e1f4.html"},{"title":"记一次线上死锁排查","text":"前段时间偶尔会收到线上MySQL死锁告警通知，由于有补偿机制，最终业务会处理成功，所以没太关心。 1Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction 最近又收到了相同的告警，可能不是偶然事件，于是开始排查。首先翻看了日志，结合代码，没有发现什么问题。事发时应该也没有什么大批量并发事件。 于是向DBA要来了deadlock log，日志内容如下: 12345678910111213141516171819202122232425262728293031323334353637383940LATEST DETECTED DEADLOCK------------------------2021-03-22 16:02:01 0x7f1cfc289700*** (1) TRANSACTION:TRANSACTION 153411874, ACTIVE 0 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 8 lock struct(s), heap size 1136, 23 row lock(s), undo log entries 22MySQL thread id 8203444, OS thread handle 139762013996800, query id 766107488 updatingupdate testSET status = 4,version = version+1,gmt_modified = '2021-03-22 16:02:01' where id = 1and version=14*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 639 page no 2931 n bits 128 index PRIMARY of table `test` trx id 153411874 lock_mode X locks rec but not gap waitingRecord lock, heap no 40 PHYSICAL RECORD: n_fields 45; compact format; info bits 0*** (2) TRANSACTION:TRANSACTION 153411876, ACTIVE 0 sec starting index readmysql tables in use 1, locked 18 lock struct(s), heap size 1136, 7 row lock(s), undo log entries 6MySQL thread id 8204162, OS thread handle 139762466330368, query id 766107489 updatingupdate test SET approval_status = 5, biz_date = '2021-02-23 00:00:00', modified_id = 123, modified_name = 'xxx', contact_company_id = 456, contact_company_n*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 639 page no 2931 n bits 128 index PRIMARY of table `test` trx id 153411876 lock_mode X locks rec but not gapRecord lock, heap no 40 PHYSICAL RECORD: n_fields 45; compact format; info bits 0*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 639 page no 2931 n bits 128 index PRIMARY of table `test` trx id 153411876 lock_mode X locks rec but not gap waitingRecord lock, heap no 28 PHYSICAL RECORD: n_fields 45; compact format; info bits 0 上面日志只保留了关键部分，表名等也进行了脱敏。可以看到两个事务都在等待PRIMARY也就是主键索引 1RECORD LOCKS space id 639 page no 2931 n bits 128 index PRIMARY of table `test` 然后再结合日志中的SQL和代码，发现问题的原因如下: 一共涉及3个系统，分别是S、C、F，在S系统中有一个业务操作完成后会给C，F发消息，C收到S的消息处理完成后也会给F发一个消息，如图所示: 在F中几乎同时开启了两个事务，并且两个消息在F中涉及的记录是相同的，id分别是1，2，表为test。于是出现了事务一: 12345SQL1:update test set status = 4 ...... where id=1SQL2:update test set status = 4 ...... where id=2 事务二: 12345SQL1:update test SET approval_status = 5 ...... where id =2SQL2:update test SET approval_status = 5 ...... where id =1 事务一先持有id=1的锁，事务二持有id=2的锁，事务一尝试获取id=2的锁，事务二尝试获取id=1的锁，所以死锁了。最后MySQL回滚了事务二。 发生这种情况是由于产品和系统设计不合理导致的，目前正在重构中。 如果下次再发生死锁直接看deadlock log吧，没必要浪费时间翻代码看业务日志了。","link":"/archives/9e47523f.html"},{"title":"读取Jar中指定目录下的所有文件","text":"读取Jar中文件使用类似getResourceAsStream等以流的方式获取即可。但是想要读取Jar中某个目录下的所有文件却不是那么容易。 第一种方式首先要读取Jar中的目录下的文件，得先搞清楚Jar中的目录结构，例如常见的SpringBoot打包后的Jar中目录如下： 假如我们要读取的目录是BOOT-INF/classes/processes（对应源文件目录是resources/processes） 代码如下： 123456789101112131415161718192021222324//获取当前Jar文件路径URL url = this.getClass().getClassLoader().getResource(&quot;&quot;); String jarPath = url.toString().substring(0, url.toString().indexOf(&quot;!/&quot;) + 2); log.info(&quot;jarPath:{}&quot;, jarPath); URL jarURL = new URL(jarPath); JarURLConnection jarCon = (JarURLConnection) jarURL.openConnection(); JarFile jarFile = jarCon.getJarFile();//获取Jar下所有文件 Enumeration&lt;JarEntry&gt; entries = jarFile.entries();//遍历文件 while (entries.hasMoreElements()) { JarEntry jarEntry = entries.nextElement(); //获取文件路径 String innerPath = jarEntry.getName(); log.info(&quot;jarEntry Name:{}&quot;, innerPath); //判断是否需要处理的目录下的文件，PROCESSES=BOOT-INF/classes/processes if (innerPath.startsWith(PROCESSES) &amp;&amp; !jarEntry.isDirectory()) { //获取到文件流 InputStream inputStream = this.getClass().getClassLoader().getResourceAsStream(innerPath); //doSomething //...... } }} 此方式优缺点：无第三方库依赖，用的都是JDK 相关API。但是只能在jar模式下运行，本地调试会出错。 第二种方式如果有使用到Spring，那么不管是打成Jar运行还是本地运行，获取指定目录中的文件就很简单了。主要是利用了Spring 的ResourcePatternResolver，详细代码如下： 1234567891011121314151617 List&lt;Resource&gt; resourceList = new ArrayList&lt;&gt;();//PROCESS_DEFINITION_LOCATION_SUFFIXES = Arrays.asLIst(&quot;**.bpmn20.xml&quot;,&quot;**.bpmn&quot;) for (String suffix : PROCESS_DEFINITION_LOCATION_SUFFIXES) { //PROCESS_DEFINITION_LOCATION_SUFFIXES = classpath://processes/ //拼接路径pattern String path = PROCESS_DEFINITION_LOCATION_PREFIX + suffix; //通过ResourcePatternResolver获取资源文件, //resourceLoader = @Autowired ResourcePatternResolver resourceLoader Resource[] resources = resourceLoader.getResources(path); if (resources != null &amp;&amp; resources.length &gt; 0) { resourceList.addAll(Arrays.asList(resources)); } }//通过resource.getInputStream()即可获取文件流//doSomething//...... 此方式优缺点，依赖了Spring框架，但是对运行环境没有要求。 总结： 推荐使用第二种方式，毕竟现在基本上都会使用到Spring。","link":"/archives/f728629b.html"},{"title":"TypeSafe Config","text":"Typesafe的Config库，纯Java写成、零外部依赖、代码精简、功能灵活、API友好。支持Java properties、JSON、JSON超集格式HOCON以及环境变量。它也是Akka的配置管理库. 默认加载classpath下的application.conf,application.json和application.properties文件。通过ConfigFactory.load()加载 也可指定文件地址： 1ConfigFactory.load(confFileName) 合并多个文件： 12345ConfigfirstConfig=ConfigFactory.load(&quot;test1.conf&quot;);ConfigsecondConfig=ConfigFactory.load(&quot;test2.conf&quot;);//a.withFallback(b)a和b合并，如果有相同的key，以a为准ConfigfinalConfig=firstConfig.withOnlyPath(&quot;host&quot;).withFallback(secondConfig); 未完待续……","link":"/archives/585899c0.html"},{"title":"被隔离的第7天","text":"被隔离的第7天，每天接到无数个部门的电话，量体温，报情况。","link":"/archives/3eda1a9.html"},{"title":"《Java性能-权威指南》 笔记","text":"在做性能测试时，需要确保输入参数是确定的，否则处理参数还会带来一定的性能损耗。 JVM主要接受两类标志（少数例外）：布尔标志和附带参数标志。 布尔标志语法：-XX:+FlagName表示开启，-XX:-FlagName表示关闭。 附带参数标志语法：-XX:FlagName=something。例如-XX:NewRadio=N。 系统级监控命令 vmstat，关注cs 上下文切换次数，us用户CPU时间，sy系统CPU时间。 JDK常用小工具 工具 说明 常用 jcmd 打印Java进程涉及的基本类、线程和VM信息 查看JVM版本： jcmd process_id VM.version 查看JVM调优参数：jcmd process_id VM.flags [-all] 查看程序所使用的命令行：jcmd process_id VM.command_line jstack 线程栈信息获取 统计分析线程情况：jstack pid &gt; jstack.out java ParseJStack jstack.out JIT 编译器Java是一种解释性语言，只不过解释的是class。通常认为解释性语言性能较差，但是JVM通过即时编译解决这个问题。HotSpot JVM通过编译热点代码（经常执行的代码）为机器码来提高性能，对于只执行一次的代码，编译时间可能超过了直接解释执行class的时间，JVM不会编译此类代码。 JVM对执行次数越多的代码越熟悉，优化效果更高。 选择编译器类型Java虚拟机分为Client(C1)、Server(C2)两类虚拟机(编译器)。-XX:+Printflagsfinal 开启后能获得基于环境的自动调优。 JVM Server 模式与 Client 模式启动，最主要的差别在于：-server 模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。原因是：当虚拟机运行在-client 模式的时候，使用的是一个代号为 C1 的轻量级编译器，而-server 模式启动的虚拟机采用相对重量级代号为 C2 的编译器。C2 比 C1 编译器编译的相对彻底，服务起来之后，性能更高。选择编译器的标志与大多数标志不同，标准的编译器标志是：-client 、-server 或者-d64。分层编译(tiered compilation)是个例外，常见开启方式为：-XX:+TieredCompilation。分层编译必须使用server编译器。在该模式下，代码会先被解释器执行，积累到足够热度的时候由client compiler（C1）编译，然后继续积累热度到一定程度会进一步被server compiler（C2）重新以更高的优化程度编译。一般情况下，长时间运行的应用选择分层编译，短暂运行的应用选择client较好（特别是要求启动时间快的）（JAVA8中分层编译是默认开启的）。 调优代码缓存JVM在编译代码后，会在代码缓存中保存编译之后的汇编语言指令集。代码缓存的大小固定，所以一旦填满，JVM就不能编译更多的代码了。通常Server模式需要的比Client要大，JVM默认的代码缓存大小也是如此。没有办法能够准确的测出所需要的代码缓存大小，通常的做法是简单的增加1倍或者3倍。-XX:ReservedCodeCacheSize=N标志可以设置代码缓存的最大值。-XX:InitialCodeCacheSize=N标志指定初始大小。通常只需要设置最大值即可。这里设置的大小保留内存，并不会直接分配。 编译阀值判断是否需要编译，是通过检查两种计数器（回边计数器、方法调用计数器）总数。标准编译由-XX:CompileThreshold=N标志触发。client默认值是1500，server默认值是10000。计数器会随着时间而减少，对于偶尔执行的方法可能永远达不到阀值。 编译日志通过-XX:+PrintCompilation可以启用编译日志。也可以通过jstat -compiler process_id了解编译情况。另外也可以通过jstat -printcompilation process_id intevel_time(1000毫秒)标志来获取最近被编译的方法。 方法内联，Java执行方法就是栈帧的入栈出栈，栈帧包含局部变量表，操作数栈，动态链接，返回值。入栈出栈相对来说比较耗时，所以对一些简单的方法，在编译的时候会直接用函数体替换调用方法。 关于final，几乎所有的人都说添加final后有利于JIT做方法内联和其他优化。确实在很久很久以前是这样的。现在加不加final对性能都没有影响。但是如果确实有final的语义要求还是要加上的。 垃圾收集现在主流的四个收集器分别是：Serial 收集器（常用于单CPU环境）、Throughput（或者Parallel）收集器、Concurrent 收集器（CMS）和G1收集器。 垃圾收集的基本操作是找到不再使用的对象，回收它们使用的内存，对堆的内存布局进行压缩。完成这些操作不同的收集器采用了不同的方法。 PS：不再使用的对象通过引用计数来确定不再使用的对象，关于循环引用的对象，通过遍历GC Root（线程，Classloader等）引用的对象来确定不再使用的对象。 如果进行垃圾收集时， 必须确保线程不再使用这些对象，所有应用线程都停止运行所产生的停顿被称为时空停顿（stop-the-world）。通常这些停顿对应用的性能影响最大，调优垃圾收集时，尽量减少这种停顿是最为关键的考量因素。 分代垃圾收集器在Java中使用临时对象的情况非常多 ，对象被快速的创建和丢弃。所以垃圾收集器设计时就特别考虑到这点。新生代（Eden、Survivor）是堆的一部分，对象首先在新生代中分配。新生代填满时，垃圾收集器会暂停所有的应用线程，回收新生代空间。不再使用的对象被回收，仍然使用的对象会被移动到其他地方。这种操作称为Minor GC。采用这种设计有两个性能上的优势。其一，由于新生代仅仅是堆的一部分，与处理整个堆相比，处理新生代速度更快。意味着应用线程停顿的时间会更短。但是也意味着更频繁的发生停顿。然后就目前而言，更短的停顿显然能带来更多的优势，即使发生的频率更高。第二个优势源于新生代中对象的分配方式。对象分配于Eden空间。垃圾收集时，Eden空间中的对象要么被移走，要么被回收。所有的存活对象要么被移动到另外一个Survivor空间，要么被移动到老年代。相当于新生代空间在垃圾收集时自动进行了一次压缩整理。所有垃圾收集算法在对新生代进行垃圾回收时都存在“stop-the-world”现象。对象不断的往老年代移动，老年代早晚也会满，JVM需要找出老年代中不再被使用的对象，这时垃圾收集器的差别就体现出来了。简单的算法直接停掉所有的应用线程，找出不再使用的对象回收掉。接着对堆空间进行整理。这个过程称为Full GC。通常导致应用线程长时间停顿。另一方面，CMS和G1收集器可以在应用线程运行的同时找出不再使用的对象。由于这种特性，这两种收集器也被称为Concurrent收集器。将停顿降到了最低，也称为低停顿（Low-pause）收集器。但是其代价是带来更多的CPU消耗。当然这两种收集器也可能遭遇长时间的Full GC。我们要做的就是避免这样的停顿。 收集器 开启方式 描述 Serial Client型虚拟机默认开启 最简单的收集器，使用单线程，无论哪种GC，所有的应用线程都会被暂停。通过开启其他收集器来关闭 Throughput Server型虚拟机默认开启（JDK7u4+），有需要可以通过-XX:+UseParallelGC、-XX:+UseParallelOldGC启用 使用多线程，也被称为Parallel 收集器。无论哪种GC，所有的应用线程都会被暂停。 CMS -XX:+UseConcMarkSweepGC、-XX:+UseParNewGC Minor GC暂停所有应用线程，Full GC不暂停，使用后台线程扫描老年代回收垃圾对象，付出的代价是CPU使用率更高，堆更加碎片化，等到没有连续的空间分配对象时，会蜕化成Serial收集器的行为。 G1 -XX:+UseG1GC 收集的方式同CMS，区别是老年代被划分不同的区域，通过区域间的复制移动完成对象清理工作。意味着实现了堆的部分压缩整理，减少碎片化发生。 收集器没有绝对的好坏，取决于应用程序的特征，以及应用的性能目标。 如果应用程序所需的CPU并不多，并且有足够的CPU资源，考虑Concurrent（CMS、G1）收集器性能更高。否则只会增加应用程序负担。CMS和G1，当堆较小时(4G&lt;)选择CMS，因为CMS会扫描整个老年代，而G1是多线程分区域扫描。 GC调优 调整堆的大小选择堆的大小是一种平衡，分配的过小，程序的大部分消耗可能都在GC上。如果粗暴的设置一个很大的堆，将会增加GC停顿的时间，GC的频率虽然下降了，但是持续长时间的停顿也会让程序的整体性能变慢。另外超大堆还有可能导致系统使用虚拟内存。因此，调整堆（机器上所有堆）大小时首先的原则就是不超过物理内存大小。 除此之外还需要考虑为JVM自身和其它应用预留内存。堆的大小由两个参数控制：初始值（-Xms N）和最大值（-Xmx N）。JVM会根据需要自动调整堆大小，直至达到最大值。如果将初始值与最大值设置为相同，JVM不再需要推算需要的堆大小，可以稍微提高GC的运行效率。 代空间的调整一旦堆的大小确定下来，就需要决定新生代和老年代的大小。新生代过大，垃圾收集（Minor GC）的频率就低，转移到老年代的对象就少。但是老年代就容易满，一旦老年代满了就触发Full GC。（Full GC代价更大）-XX:NewRatio=N（默认2）设置新生代和老年的占用的比例。-XX:NewSize=N设置新生代初始大小。-XX:MaxNewSize=N设置新生代最大大小。-XmnN 同时设置新生代初始大小和最大大小。NewRatio计算空间的公式： Initial young Gen Size = Initial Heap Size / (1+NewRatio)可以看出默认情况下，新生代占的比例为33%。 永久代和元空间 JVM载入类的时候，他需要记录这些类的元数据。这部分数据被保存在一个单独的堆空间里。在Java 7 中称为永久代（Permgen），在Java 8 中称为元空间（Metaspace）。设置永久代大小：-XX:PermSize=N、-XX:MaxPermSize=N设置元空间大小（默认没有限制）：-XX:MetaspaceSize=N、-XX:MaxMetaspaceSize=N 垃圾回收工具观察垃圾回收对性能的影响最好的方法就是熟悉GC日志。开启GC日志的方法有多种，包括-verbose:gc或者-XX:+PrintGC，这两个都能创建基本的GC日志。使用-XX:+PrintGCDetails会创建更详细的GC日志（推荐）。同时还可以使用-XX:+PrintGCTimeStamps或者-XX:+PrintGCDateStamps查看几次GC操作之间的时间（推荐）。默认情况下GC日志直接输出到标准输出，不过使用-Xloggc:filename 标志可以修改输出到某个文件。对于长时间运行的应用来说，通过-XX:+UseGCLogfileRotation、-XX:NumberOfGCLogfiles=N、-XX:GCLogfileSize=N标志可以控制日志循环。避免日志文件过大。可以通过GC Histogram 分析日志。也可以通过脚本的方式获取GC数据，jstat是理想的工具。其中最常用的一个选项是-gcutil。例如： jstat -gcutil process_id 1000 命令将1秒输出一次GC情况。输出的结果大致如下： S0（Survivor0）、S1(Survivor1)、E(Eden)、O(Old)、P(Permgen)值为各区域所在大小比例。YGC、YGCT为Young GC的次数和GC的时间。FGC、FGCT为Full GC的次数和时间。GCT为总GC时间。 S0、S1又被称为 To / From Space。GC时，针对一些刚被创建的活跃对象，如果直接移动到老年代，似乎不太合理，会导致老年代更容易充满，从而引发Full GC。于是就有了S0、S1空间。当年轻代发生GC时，Eden中的活跃对象会被转移到S0，下次GC新的存活对象则会和S0中的活跃对象一起被转移到S1。当S0或者S1空间不足，对象则会被转移到老年代。或者S0，S1中对象转移次数达到了阀值（-XX:InitialTenuringThreshold=N），也会被转移到老年代。 GC日志格式： 1[GC (Allocation Failure) [PSYoungGen: 89580K-&gt;12786K(89600K)] 147723K-&gt;88825K(183296K), 0.1986863 secs] [Times: user=0.33 sys=0.05, real=0.20 secs] 1[Full GC (Ergonomics) [PSYoungGen: 12786K-&gt;0K(89600K)] [ParOldGen: 76039K-&gt;86431K(187904K)] 88825K-&gt;86431K(277504K), [Metaspace: 3611K-&gt;3611K(1056768K)], 1.0945902 secs] [Times: user=2.36 sys=0.06, real=1.10 secs] 可以观察到各个空间回收情况以及用时。 存活对象越多GC的效率越差，意味着要慎重的使用对象重用。但是在某些情况下，例如JDBC连接池，创建连接的成本非常高，与增加的GC时间权衡，重用更为高效。 线程与同步性能所有线程池的工作方式本质是一样的： 有一个队列，任务被提交到这个队列中（可以不止一个队列，概念是一样的）。一定数量的线程会从该队列中取任务，然后执行。 执行完任务后，线程返回队列检索另外一个任务。 设置最大线程数并不是线程数越多越好，最大线程数设置没有什么诀窍，只能通过充分的测试得出（如果不是CPU密集型应用，而系统出现的负载是由外部导致，例如增多的请求数，此时增加线程数也许是个不错的选择。）。 设置最小线程数需要评估线程池平均的任务数量，如果平均任务数量只有20，而最小线程数却有2000，那么1980个线程就会空闲，白白浪费资源。也不能非常武断的将最小线程数设置为1，这样会导致线程频繁创建，影响性能。 线程池任务大小线程池任务队列大小设置也没有什么诀窍，只能通过测量真实应用来得出大小。如果设置的特别大，例如Integer.MAX_VALUE，当任务数量很大，线程又来不及处理，则有可能导致资源耗尽。 3种线程池队列Java ThreadPoolExecutor的行为根据队列所使用的类型表现有所不同。 SynchronousQueue ，如果使用的是这种类型的队列，那么线程池的表现和通用的线程池表现一致：初始创建一定的线程（最小值），如果此时来了一个新的任务，而所有的线程都在忙，则会创建一个新的线程，如果创建的线程已经达到最大值，则新的任务就会被拒绝。 LinkedBlockedingQueue，无界队列。如果使用的是这种类型的队列，线程池不会拒绝任务，因为任务队列的大小没有限制，最多仅会按照最小值创建线程。最大值被忽略。 ArrayBlockedingQueue，有界队列。如果使用的是这种类型的队列，默认按照最小值设置创建线程，当新的任务到达时，所有的线程都在忙，则新的任务会加入队列，当队列满时，则会创建新的线程来处理任务（处理队列中的第一个任务）。如果线程数量大于最大值，则新的任务会被拒绝。 ForkJoinPoolForkJoinPool是 ExecutorService的一个实现，不是为了替代ThreadPoolExecutor，而是一个补充，在某些应用场景（递归、分而治之）下性能更好。Java本身也有很多实现用到了ForkJoinPool，例如：CompletableFuture。 同步的代价 “同步”这里的意思是，代码中一段代码串行地访问一组变量，每次只有一个线程能访问内存。包括使用synchronized 关键字，也包括java.util.concurrent.lock.Lock实例保护的代码，再就是java.util.concurrent包及子包中内的代码。严格来讲，java.util.concurrent.atomic下的类并没有使用同步，它们利用了“比较与交换”(Compare And Swap，CAS)CPU指令。利用CAS线程并不会阻塞，但是开发者看上去最终还是只能串行地访问被保护被保护内存。1.同步与可伸缩性，如果程序中更多的是串行代码，那么引入更多的线程并不会带来性能提升。2.锁对象的开销，锁的竞争越大，性能消耗越高（可参考synchronized锁升级），当某个锁没有竞争时，获取锁的成本非常小。在竞争激烈时，哪怕是CAS开销也会变大。 避免同步能够避免同步尽量避免，例如每个线程使用的是不同的实例，在实例中有一个volatile变量，频繁的读写这个变量， 这毫无意义，因为此变量不存在竞争。如果的确无法避免同步，同步方案在考虑时应该如下规则：如果访问的是不存在竞争的资源，那么基于CAS的保护要稍快于传统的同步（完全不用更快）如果是轻度或者适度的竞争，那么基于CAS的保护要快于传统的同步（而且往往是快得多）如果竞争激烈，传统的同步会是更高效的选择。 JVM 线程调优每个线程都有一个原生栈，不同的JVM版本，线程栈默认的大小不同，设置较小的栈可以防止耗尽原生内存，确定是，如果调用栈特别大，会抛出StackOverflowError。如果设置较大的栈，但是又没有足够的原生内存来创建线程，也可能会抛出OutOfMemoryError。改变线程栈大小，可以使用-XssN标志（例如 -Xss256k）。 Java EE性能调优Web容器的基本性能一些适用于所有服务器的概念：1.减少输出，减少服务器产生的结果输出可以加快Web页面返回到浏览器的速度。2.减少空格，空格在传输时同样需要时间，避免在返回的结果中写入制表符和空格。3.合并静态资源，CSS和JavaScript资源保存在独立的文件中是有意义的，便于维护。但是传输一个大文件的效率要高于传输几个小文件。","link":"/archives/863caf0d.html"},{"title":"为什么苹果不自己制造芯片","text":"苹果近期发布了最新的处理器Apple A13 Bionic，由台积电代工。为什么苹果不自己制造设计出来的芯片呢？ 原来业内习惯把半导体行业的公司分为三类： fabless（无晶圆芯片设计厂）：这样的公司只设计芯片，不自己制造芯片。最大的fabless企业有高通、博通、AMD、联发科、搭上人工智能这波热点最近火的不行的Nvidia等等。国内的fabless企业有收购了展讯和锐迪科的清华紫光、华为海思等。Foundry（代工厂）：这样的公司专门为别人制造芯片。最大的Foundry企业有台积电（TSMC）、GlobalFoundry、UMC等。国内最大的是中芯国际。随着工艺进步到20nm以下，从平面晶体管向三维FinFET演化，新一代工艺所需要的投资越来越大，已经只有少数几个玩家能玩得起了（台积电、三星、Intel）。国内的中芯国际跟台积电有几代的差距。中芯国际目前商用的最先进工艺是28nm，台积电16nm已经大规模商用，7nm也马上就要用起来。IDM（制造垂直整合）：这样的公司既设计芯片，也自己制造芯片。最大的有Intel和三星。 这样做的好处是，分担风险，苹果不用花费巨大投资建立生产线，因此轻资产，灵活性高，可以对市场快速反应，活力足。 再说另外一个问题，为什么主流的手机处理器厂商中很少见到英特尔呢？首先提一下CPU的简单构成：ALU（算术逻辑单元）、控制单元、寄存器控制单元通过时钟控制着指令执行的节奏，将指令加载存放在寄存器、并通过ALU计算。这里提到了指令，指令基本上分为两类：RISC（精简指令集） 、CISC （复杂指令集），指令越复杂意味着能耗越高，试想一下，在目前手机电池技术还未突破的情况下，手机CPU会上CISC吗？上面说的两个指令集的典型代表就是ARM和x86，ARM是目前主流的手机CPU架构，也就是精简指令。而x86才是英特尔等厂商的强项。也许是英特尔出于战略考虑放弃了移动处理器这块蛋糕，或者说英特尔没有意料到这块蛋糕这么大。不过，目前App背后对应的还是各种Server，Server离不开x86。 参考资料：https://www.zhihu.com/question/68283951/answer/262481048https://www.zhihu.com/question/20148756","link":"/archives/52360944.html"},{"title":"关于Paxos那些点","text":"世界上只有一种共识协议，就是 Paxos，其他所有共识算法都是 Paxos 的退化版本。 Paxos分为Basic Paxos、Multi Paxos、和其它演进版本。 Basic Paxos前提：Basic Paxos 只能对单个值形成决议。 Paxos 算法将分布式系统中的节点分为三类： 提案节点：称为 Proposer，提出对某个值进行设置操作的节点，设置值这个行为就被称之为提案（Proposal），值一旦设置成功，就是不会丢失也不可变的。请注意，Paxos 是典型的基于操作转移模型而非状态转移模型来设计的算法，这里的“设置值”不要类比成程序中变量赋值操作，应该类比成日志记录操作，在后面介绍的 Raft 算法中就直接把“提案”叫作“日志”了。 决策节点：称为 Acceptor，是应答提案的节点，决定该提案是否可被投票、是否可被接受。提案一旦得到过半数决策节点的接受，即称该提案被批准（Accept），提案被批准即意味着该值不能再被更改，也不会丢失，且最终所有节点都会接受该它。 记录节点：被称为 Learner，不参与提案，也不参与决策，只是单纯地从提案、决策节点中学习已经达成共识的提案，譬如少数派节点从网络分区中恢复时，将会进入这种状态。 Paxos 算法包括两个阶段，其中，第一阶段“准备”（Prepare）就相当于上面抢占锁的过程（不是基于互斥量）。如果某个提案节点准备发起提案，必须先向所有的决策节点广播一个许可申请（称为 Prepare 请求）。提案节点的 Prepare 请求中会附带一个全局唯一的数字 n 作为提案 ID，决策节点收到后，将会给予提案节点两个承诺与一个应答。 两个承诺是指： 承诺不会再接受提案 ID 小于或等于 n 的 Prepare 请求。 承诺不会再接受提案 ID 小于 n 的 Accept 请求。 一个应答是指： 不违背以前作出的承诺的前提下，回复已经批准过的提案中 ID 最大的那个提案所设定的值和提案 ID，如果该值从来没有被任何提案设定过，则返回空值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Prepare 请求不予理会。 当提案节点收到了多数派决策节点的应答（称为 Promise 应答）后，可以开始第二阶段“批准”（Accept）过程，这时有如下两种可能的结果： 如果提案节点发现所有响应的决策节点此前都没有批准过该值（即为空），那说明它是第一个设置值的节点，可以随意地决定要设定的值，将自己选定的值与提案 ID，构成一个二元组“(id, value)”，再次广播给全部的决策节点（称为 Accept 请求）。 如果提案节点发现响应的决策节点中，已经有至少一个节点的应答中包含有值了，那它就不能够随意取值了，必须无条件地从应答中找出提案 ID 最大的那个值并接受，构成一个二元组“(id, maxAcceptValue)”，再次广播给全部的决策节点（称为 Accept 请求）。 当每一个决策节点收到 Accept 请求时，都会在不违背以前作出的承诺的前提下，接收并持久化对当前提案 ID 和提案附带的值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Accept 请求不予理会。 关于活锁： 两个提案节点互不相让地争相提出自己的提案，抢占同一个值的修改权限，导致整个系统在持续性地“反复横跳”，外部看起来就像被锁住了一样 Multi PaxosMulti Paxos 对 Basic Paxos 的核心改进是增加了“选主”的过程，提案节点会通过定时轮询（心跳），确定当前网络中的所有节点里是否存在有一个主提案节点，一旦没有发现主节点存在，节点就会在心跳超时后使用 Basic Paxos 中定义的准备、批准的两轮网络交互过程，向所有其他节点广播自己希望竞选主节点的请求，希望整个分布式系统对“由我作为主节点”这件事情协商达成一致共识，如果得到了决策节点中多数派的批准，便宣告竞选成功。当选主完成之后，除非主节点失联之后发起重新竞选，否则从此往后，就只有主节点本身才能够提出提案。此时，无论哪个提案节点接收到客户端的操作请求，都会将请求转发给主节点来完成提案，而主节点提案的时候，也就无需再次经过准备过程，因为可以视作是经过选举时的那一次准备之后，后续的提案都是对相同提案 ID 的一连串的批准过程。也可以通俗理解为选主过后，就不会再有其他节点与它竞争，相当于是处于无并发的环境当中进行的有序操作，所以此时系统中要对某个值达成一致，只需要进行一次批准的交互即可 可能有人注意到这时候的二元组(id, value)已经变成了三元组(id, i, value)，这是因为需要给主节点增加一个“任期编号”，这个编号必须是严格单调递增的，以应付主节点陷入网络分区后重新恢复，但另外一部分节点仍然有多数派，且已经完成了重新选主的情况，此时必须以任期编号大的主节点为准。当节点有了选主机制的支持，在整体来看，就可以进一步简化节点角色，不去区分提案、决策和记录节点了，统统以“节点”来代替，节点只有主（Leader）和从（Follower）的区别 来源http://icyfenix.cn/distribution/consensus/paxos.html http://icyfenix.cn/distribution/consensus/raft.html https://acehi.github.io/thesecretlivesofdata-cn/raft/","link":"/archives/e00e37d3.html"},{"title":"命令收藏","text":"mac关闭SPI(获取根目录写权限) 重启 command+R 进入恢复界面 实用工具 - 终端 输入：csrutil disable 重启：reboot 打开终端，挂载根目录：sudo mount -uw / 查看端口 1lsof -i:9999 brew更新app1brew cu -a -f jdk保存堆快照1jmap -dump:format=b,file=heapdump.hprof pid","link":"/archives/afa41a9c.html"},{"title":"常见集群方式","text":"主从（master-slave）写master，同步到slave 。slave可用于读。常见mysql，redis。 哨兵在主从的基础上，添加了master宕机时，slave自动切换为master。 cluster集群内每个节点都是分片。通过分布式一致性协议沟通。 例如redis，通过Gossip 协议，在集群内同步，各个分片的哈希槽信息。 便于重定向请求。","link":"/archives/6a6e8ff1.html"},{"title":"elasticsearch 提示Parse Failure [No mapping found for [filed] in order to sort on]] 的解决办法","text":"排序代码如下：{ &quot;sort&quot;: [ { &quot;timestamp&quot;: { &quot;order&quot;: &quot;desc&quot; } } ] } 修改后：{ &quot;sort&quot;: [ { &quot;timestamp&quot;: { &quot;order&quot;: &quot;desc&quot;, &quot;ignore_unmapped&quot;: true } } ] }","link":"/archives/2a3d9fc7.html"},{"title":"flume同时使用KafkaSource、KafkaSink导致的问题","text":"KafkaSource 配置topic：topic1KafkaSink 配置topic：topic2从topic1拉取数据，经过简单处理后发到topic2但是你会发现flume一直在循环读写topic1原因就是KafkaSink中的这段代码： 123if (eventTopic == null) { eventTopic = topic;} 首先从headers中获取TOPIC_HEADER(topic),然后优先使用。然而在KafkaSource中则会将topic1 PUT到Header中，所以导致循环读写topic1。 如何解决呢？ 你可以重新KafkaSink，改掉上面那段代码。 或者配置一个拦截器，将KafkaSource 写到Header中的topic给替换掉： 1234agent.sources.so1.interceptors.i1.type = staticagent.sources.so1.interceptors.i1.key = topicagent.sources.so1.interceptors.i1.preserveExisting = falseagent.sources.so1.interceptors.i1.value = topic2","link":"/archives/545f6758.html"},{"title":"kafka那些坑","text":"千万别用高版本的kafka client 去连低版本的kafka server。否则回报一系列的(n)io异常，比如下面这个异常 java.nio.BufferUnderflowException 不丢消息：producer有个ack参数，有三个值，分别代表：不在乎是否写入成功、写入leader成功、写入leader和所有reclpica成功；要求非常可靠的话可以牺牲性能设置成最后一种。不重复发送：正常发都不会重复，只可能丢，看你这边怎么容错重发了，参考上一条。消息只读一次：同样，正常读不会重复，如果在上一次读的过程中发生了异常，消息可能被消费，但是offset没有及时commit；这本身是两步，存在中间crash的风险","link":"/archives/eb616fac.html"},{"title":"mongodb 备份数据","text":"备份[部分]数据为dump，然后从collection中将已备份数据删除。 ./mongodump -d trans -c test -h 192.168.190.128 -u trans -p 123456 -o /data/backup -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 -c:指明collection的名字 -o:指明到要导出的文件名 -q:指明导出数据的过滤条件 恢复备份的数据./bin/mongorestore -h host -d test --drop data/backup/test/ -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 –drop 为先删除collection中的数据再恢复","link":"/archives/5c2c1bbd.html"},{"title":"mongodb13亿数据清理记录","text":"mongodb上一个collection数据已经膨胀到13亿，也就最近一两个月的数据重要一点。于是考虑清除一下这个collection。于是：第一步：先将原表备份 1db.test.renameCollection(&quot;test_bak&quot;) 然后根据时间删除数据 1db.test_bak.remove({&quot;createtime&quot;:{&quot;$lte&quot;:ISODate(&quot;2019-06-09T00:00:00.000Z&quot;)}}) 将两个月前的数据全部清掉。执行到这一步发现，现实很残酷，基本上命令是卡死状态。查看collection上的索引： 1db.test_bak.getIndexes() 发现createtime没有索引，于是乎加上： 1db.test_bak.createIndex({&quot;createtime&quot;:-1}) 加索引这一步也要执行很久，慢慢等吧。等到索引添加成功再次执行删除数据的命令即可，也将执行很久。通过： 1db.test_bak.count() 查看还剩多少数据。由于test_bak已经没有新的数据写入，还需要将最近两个月的数据同步到test中，于是： 123db.test_bak.find({&quot;createtime&quot;:{&quot;$gte&quot;:ISODate(&quot;2019-06-09T00:00:00.000Z&quot;)}}).forEach(function(x){ db.test.insert(x);}) 等待慢慢执行吧….. 以上为实操分享。 所在在一开始就应该设置，无用的数据自动清理掉。也就没有后面头疼的问题了。","link":"/archives/7fbe8b08.html"},{"title":"关闭代码块移动","text":"Mac 开启了三指拖拽，发现在IDEA的某些Project中，选中代码块时，老是拖动代码。解决办法： 1Editor –&gt; General -&gt; Enable Drag’n’Drop functionality in Editor 关闭即可。","link":"/archives/7f244d3f.html"},{"title":"博客用的图床挂了","text":"之前不想把博客里面的图片也一同上传，用了utools里面一个默认的免费图床，结果今天发现好像图床挂掉了。之前写的博客里面的图片全挂了。。。果断换了gitee做新的图床。 这不会再挂了吧。。。","link":"/archives/2baffaa5.html"},{"title":"linux 大文件无法清空","text":"linux 清空一个大文件（上G的）一般有这么几种方法： cat /dev/null &gt; nohup.log cp /dev/null &gt; nohup.log echo “” &gt; nohup.log 但是今天在尝试这几个命令的时候发现始终无法清空。 最终发现问题在nohup.log的生成命令那里：nohup xxx &gt; nohup.out &amp;问题就在 &gt; ，需要使用 &gt;&gt; 追加模式才能使用上述三个命令清空。正确方式：nohup xxx &gt;&gt; nohup.out &amp; 其实，应该将nohup.out进行拆分。或者不输入到nohup.out。因为毕竟程序里面已经使用了log库。","link":"/archives/5cc761d2.html"},{"title":"更换电脑后hexo deploy访问出现404的问题","text":"更换电脑后重新拉下hexo相关sources，安装完成hexo-cli以及hexo-deployer-git和其他node_modules。 执行hexo clean &amp;&amp; hexo g 然后执行hexo d。 完成后发现访问出现404，提示There isn’t a GitHub Pages site here. 并且github发了大量警告邮件，有得没得，例如： 1You are attempting to use a Jekyll theme, &quot;icarus&quot;, which is not supported by GitHub Pages. 定位问题： 查看github pages对应repository，发现里面的文件完全不正确，不是hexo g生成的文件。而变成了博客对应的源文件。 查看文件是否正确生成，public目录下正确生成。 通过上面两个步骤，说明问题出在deploy。 解决问题： 删除.deploy_git，重新hexo d，一切恢复正常。","link":"/archives/32745de6.html"},{"title":"被Chrome一个bug坑了","text":"相信Chrome浏览器开发者工具中的Preview你不陌生，但是就这玩意有一个bug。 事情是这样的，前端跟我说你接口有bug，返回的数据不正确。听到bug，我反手就是一个你会不会用。 他发来了一个截图： 我给他返回的json中有一个max字段，值是100000000000000 ,正确的应该是99999999999999.99999999999999999999,你先别管为什么是这么个值。 好了，他拿出证据了，我开始怀疑真的是哪里写的有问题了，一顿查找，发现TMD哪里都没有问题啊，怎么可能，怎么会呢？ 中午的饭都不香了。 我开始怀疑是网关的问题，网关大佬说没问题。。。。。 于是拿着请求地址，curl了一下，max:99999999999999.99999999999999999999。卧槽。。。又对了？ 于是我开始怀疑最不可能出问题的浏览器，直到我点开了Response : 。。。。。。 反手就是给提了一个bug：","link":"/archives/6e43fa1b.html"}],"tags":[{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"OCR","slug":"OCR","link":"/tags/OCR/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"CAP","slug":"CAP","link":"/tags/CAP/"},{"name":"IDEA","slug":"IDEA","link":"/tags/IDEA/"},{"name":"BUG","slug":"BUG","link":"/tags/BUG/"},{"name":"Maven","slug":"Maven","link":"/tags/Maven/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"RocketMQ","slug":"RocketMQ","link":"/tags/RocketMQ/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Activiti","slug":"Activiti","link":"/tags/Activiti/"},{"name":"Mybatis","slug":"Mybatis","link":"/tags/Mybatis/"},{"name":"ASM","slug":"ASM","link":"/tags/ASM/"},{"name":"Deadlock","slug":"Deadlock","link":"/tags/Deadlock/"},{"name":"Paxos","slug":"Paxos","link":"/tags/Paxos/"},{"name":"一致性","slug":"一致性","link":"/tags/%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"flume","slug":"flume","link":"/tags/flume/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"MongodDB","slug":"MongodDB","link":"/tags/MongodDB/"},{"name":"图床","slug":"图床","link":"/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"博客","slug":"博客","link":"/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"Chrome","slug":"Chrome","link":"/tags/Chrome/"}],"categories":[{"name":"Docker随记","slug":"Docker随记","link":"/categories/Docker%E9%9A%8F%E8%AE%B0/"},{"name":"Golang随记","slug":"Golang随记","link":"/categories/Golang%E9%9A%8F%E8%AE%B0/"},{"name":"Python随记","slug":"Python随记","link":"/categories/Python%E9%9A%8F%E8%AE%B0/"},{"name":"区块链","slug":"区块链","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"Java随记","slug":"Java随记","link":"/categories/Java%E9%9A%8F%E8%AE%B0/"},{"name":"工具分享","slug":"工具分享","link":"/categories/%E5%B7%A5%E5%85%B7%E5%88%86%E4%BA%AB/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"踩坑记录","slug":"踩坑记录","link":"/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}]}